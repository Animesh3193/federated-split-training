{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinu/anaconda3/envs/mlenv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libjpeg.so.8: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "from monai import data, transforms as mt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target/crop shape for the images and masks when training\n",
    "tar_shape = (256, 256)\n",
    "crop_shape = (224, 224)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dict_args = {\n",
    "    \"random_seed\": 42,\n",
    "    \"checkpoint\": \"output_model\",\n",
    "    \"predict_mode\": False,\n",
    "    \"workers\": 4,\n",
    "    \"batch_size\": 2,\n",
    "    \"max_epoch\": 3,\n",
    "    \"lr\": 1e-3,\n",
    "    \"decay\": 1e-3,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"min_lr\": 5e-7,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\"\n",
    "    }\n",
    "\n",
    "def normalize(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 num_heads,\n",
    "                 proj_drop=0.0,\n",
    "                 kernel_size=3,\n",
    "                 stride_kv=1,\n",
    "                 stride_q=1,\n",
    "                 padding_kv=\"same\",\n",
    "                 padding_q=\"same\",\n",
    "                 attention_bias=True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.stride_kv = stride_kv\n",
    "        self.stride_q = stride_q\n",
    "        self.num_heads = num_heads\n",
    "        self.proj_drop = proj_drop\n",
    "        \n",
    "        self.conv_q = nn.Conv2d(channels, channels, kernel_size, stride_q, padding_q, bias=attention_bias, groups=channels)\n",
    "        self.layernorm_q = nn.LayerNorm(channels, eps=1e-5)\n",
    "        self.conv_k = nn.Conv2d(channels, channels, kernel_size, stride_kv, stride_kv, bias=attention_bias, groups=channels)\n",
    "        self.layernorm_k = nn.LayerNorm(channels, eps=1e-5)\n",
    "        self.conv_v = nn.Conv2d(channels, channels, kernel_size, stride_kv, stride_kv, bias=attention_bias, groups=channels)\n",
    "        self.layernorm_v = nn.LayerNorm(channels, eps=1e-5)\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=channels, \n",
    "                                               bias=attention_bias, \n",
    "                                               batch_first=True,\n",
    "                                               # dropout = 0.0,\n",
    "                                               num_heads=1)#num_heads=self.num_heads)\n",
    "\n",
    "    def _build_projection(self, x, qkv):\n",
    "\n",
    "        \n",
    "        if qkv == \"q\":\n",
    "            x1 = F.relu(self.conv_q(x))\n",
    "            x1 = x1.permute(0, 2, 3, 1)\n",
    "            x1 = self.layernorm_q(x1)\n",
    "            proj = x1.permute(0, 3, 1, 2)\n",
    "        elif qkv == \"k\":\n",
    "            x1 = F.relu(self.conv_k(x))\n",
    "            x1 = x1.permute(0, 2, 3, 1)\n",
    "            x1 = self.layernorm_k(x1)\n",
    "            proj = x1.permute(0, 3, 1, 2)            \n",
    "        elif qkv == \"v\":\n",
    "            x1 = F.relu(self.conv_v(x))\n",
    "            x1 = x1.permute(0, 2, 3, 1)\n",
    "            x1 = self.layernorm_v(x1)\n",
    "            proj = x1.permute(0, 3, 1, 2)        \n",
    "\n",
    "        return proj\n",
    "\n",
    "    def forward_conv(self, x):\n",
    "        q = self._build_projection(x, \"q\")\n",
    "        k = self._build_projection(x, \"k\")\n",
    "        v = self._build_projection(x, \"v\")\n",
    "\n",
    "        return q, k, v\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.forward_conv(x)\n",
    "        q = q.view(x.shape[0], x.shape[1], x.shape[2]*x.shape[3])\n",
    "        k = k.view(x.shape[0], x.shape[1], x.shape[2]*x.shape[3])\n",
    "        v = v.view(x.shape[0], x.shape[1], x.shape[2]*x.shape[3])\n",
    "        q = q.permute(0, 2, 1)\n",
    "        k = k.permute(0, 2, 1)\n",
    "        v = v.permute(0, 2, 1)\n",
    "        x1 = self.attention(query=q, value=v, key=k, need_weights=False)\n",
    "        \n",
    "        x1 = x1[0].permute(0, 2, 1)\n",
    "        x1 = x1.view(x1.shape[0], x1.shape[1], np.sqrt(x1.shape[2]).astype(int), np.sqrt(x1.shape[2]).astype(int))\n",
    "        x1 = F.dropout(x1, self.proj_drop)\n",
    "\n",
    "        return x1\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 # in_channels,\n",
    "                 out_channels,\n",
    "                 num_heads,\n",
    "                 dpr,\n",
    "                 proj_drop=0.0,\n",
    "                 attention_bias=True,\n",
    "                 padding_q=\"same\",\n",
    "                 padding_kv=\"same\",\n",
    "                 stride_kv=1,\n",
    "                 stride_q=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention_output = Attention(channels=out_channels,\n",
    "                                         num_heads=num_heads,\n",
    "                                         proj_drop=proj_drop,\n",
    "                                         padding_q=padding_q,\n",
    "                                         padding_kv=padding_kv,\n",
    "                                         stride_kv=stride_kv,\n",
    "                                         stride_q=stride_q,\n",
    "                                         attention_bias=attention_bias,\n",
    "                                         )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.layernorm = nn.LayerNorm(self.conv1.out_channels, eps=1e-5)\n",
    "        self.wide_focus = Wide_Focus(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.attention_output(x)\n",
    "        x1 = self.conv1(x1)\n",
    "        x2 = torch.add(x1, x)\n",
    "        x3 = x2.permute(0, 2, 3, 1)\n",
    "        x3 = self.layernorm(x3)\n",
    "        x3 = x3.permute(0, 3, 1, 2)\n",
    "        x3 = self.wide_focus(x3)\n",
    "        x3 = torch.add(x2, x3)\n",
    "        return x3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Wide_Focus(nn.Module): \n",
    "    \"\"\"\n",
    "    Wide-Focus module.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\", dilation=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\", dilation=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = F.gelu(x1)\n",
    "        x1 = F.dropout(x1, 0.1)\n",
    "        x2 = self.conv2(x)\n",
    "        x2 = F.gelu(x2)\n",
    "        x2 = F.dropout(x2, 0.1)\n",
    "        x3 = self.conv3(x)\n",
    "        x3 = F.gelu(x3)\n",
    "        x3 = F.dropout(x3, 0.1)\n",
    "        added = torch.add(x1, x2)\n",
    "        added = torch.add(added, x3)\n",
    "        x_out = self.conv4(added)\n",
    "        x_out = F.gelu(x_out)\n",
    "        x_out = F.dropout(x_out, 0.1)\n",
    "        return x_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Block_decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, att_heads, dpr):\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(in_channels, eps=1e-5)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(out_channels*2, out_channels, 3, 1, padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "        self.trans = Transformer(out_channels, att_heads, dpr)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        x1 = x.permute(0, 2, 3, 1)\n",
    "        x1 = self.layernorm(x1)\n",
    "        x1 = x1.permute(0, 3, 1, 2)\n",
    "        x1 = self.upsample(x1)\n",
    "        x1 = F.relu(self.conv1(x1))\n",
    "        x1 = torch.cat((skip, x1), axis=1)\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        x1 = F.dropout(x1, 0.3)\n",
    "        out = self.trans(x1)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DS_out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.layernorm = nn.LayerNorm(in_channels, eps=1e-5)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, 1, padding=\"same\"),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, 1, padding=\"same\"),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\"),\n",
    "            nn.Sigmoid()\n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.upsample(x)\n",
    "        x1 = x1.permute(0, 2, 3, 1)\n",
    "        x1 = self.layernorm(x1)\n",
    "        x1 = x1.permute(0, 3, 1, 2)\n",
    "        x1 = self.conv1(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        out = self.conv3(x1)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Block_encoder_bottleneck(nn.Module):\n",
    "    def __init__(self, blk, in_channels, out_channels, att_heads, dpr):\n",
    "        super().__init__()\n",
    "        self.blk = blk\n",
    "        if ((self.blk==\"first\") or (self.blk==\"bottleneck\")):\n",
    "            self.layernorm = nn.LayerNorm(in_channels, eps=1e-5)\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=\"same\")\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "            self.trans = Transformer(out_channels, att_heads, dpr)\n",
    "        elif ((self.blk==\"second\") or (self.blk==\"third\") or (self.blk==\"fourth\")):\n",
    "            self.layernorm = nn.LayerNorm(in_channels, eps=1e-5)\n",
    "            self.conv1 = nn.Conv2d(1, in_channels, 3, 1, padding=\"same\")\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "            self.conv3 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=\"same\")\n",
    "            self.trans = Transformer(out_channels, att_heads, dpr)\n",
    "\n",
    "\n",
    "    def forward(self, x, scale_img=\"none\"):\n",
    "        if ((self.blk==\"first\") or (self.blk==\"bottleneck\")):\n",
    "            x1 = x.permute(0, 2, 3, 1)\n",
    "            x1 = self.layernorm(x1)\n",
    "            x1 = x1.permute(0, 3, 1, 2)\n",
    "            x1 = F.relu(self.conv1(x1))\n",
    "            x1 = F.relu(self.conv2(x1))\n",
    "            x1 = F.dropout(x1, 0.3)\n",
    "            x1 = F.max_pool2d(x1, (2,2))\n",
    "            out = self.trans(x1)\n",
    "            # without skip\n",
    "        elif ((self.blk==\"second\") or (self.blk==\"third\") or (self.blk==\"fourth\")):\n",
    "            x1 = x.permute(0, 2, 3, 1)\n",
    "            x1 = self.layernorm(x1)\n",
    "            x1 = x1.permute(0, 3, 1, 2)\n",
    "            x1 = torch.cat((F.relu(self.conv1(scale_img)), x1), axis=1)\n",
    "            x1 = F.relu(self.conv2(x1))\n",
    "            x1 = F.relu(self.conv3(x1))\n",
    "            x1 = F.dropout(x1, 0.3)\n",
    "            x1 = F.max_pool2d(x1, (2,2))\n",
    "            out = self.trans(x1)\n",
    "            # with skip\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCT_Head(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        h_attent_head = [2, 2, 2, 2, 2]\n",
    "        filters = [8, 16, 32, 64, 128,]\n",
    "        # number of blocks used in the model\n",
    "        blocks = len(filters)\n",
    "\n",
    "        stochastic_depth_rate = 0.0\n",
    "\n",
    "        #probability for each block\n",
    "        dpr = [x for x in np.linspace(0, stochastic_depth_rate, blocks)]\n",
    "\n",
    "        # Multi-scale input\n",
    "        self.scale_img = nn.AvgPool2d(2,2)   \n",
    "\n",
    "        # model\n",
    "        self.block_1 = Block_encoder_bottleneck(\"first\", 1, filters[0], h_attent_head[0], dpr[0])\n",
    "        self.block_2 = Block_encoder_bottleneck(\"second\", filters[0], filters[1], h_attent_head[1], dpr[1])\n",
    "        self.block_3 = Block_encoder_bottleneck(\"third\", filters[1], filters[2], h_attent_head[2], dpr[2])\n",
    "        self.block_4 = Block_encoder_bottleneck(\"fourth\", filters[2], filters[3], h_attent_head[3], dpr[3])\n",
    "        self.block_5 = Block_encoder_bottleneck(\"bottleneck\", filters[3], filters[4], h_attent_head[4], dpr[4])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Multi-scale input\n",
    "        scale_img_2 = self.scale_img(x)\n",
    "        scale_img_3 = self.scale_img(scale_img_2)\n",
    "        scale_img_4 = self.scale_img(scale_img_3)  \n",
    "\n",
    "        x = self.block_1(x)\n",
    "        print(f\"Block 1 out -> {list(x.size())}\")\n",
    "        skip1 = x\n",
    "        x = self.block_2(x, scale_img_2)\n",
    "        print(f\"Block 2 out -> {list(x.size())}\")\n",
    "        skip2 = x\n",
    "        x = self.block_3(x, scale_img_3)\n",
    "        print(f\"Block 3 out -> {list(x.size())}\")\n",
    "        skip3 = x\n",
    "        x = self.block_4(x, scale_img_4)\n",
    "        print(f\"Block 4 out -> {list(x.size())}\")\n",
    "        skip4 = x\n",
    "\n",
    "        return {\n",
    "            \"skip1\": skip1.cpu().detach().numpy(), \n",
    "            \"skip2\": skip2.cpu().detach().numpy(), \n",
    "            \"skip3\": skip3.cpu().detach().numpy(), \n",
    "            \"skip4\": skip4.cpu().detach().numpy(),\n",
    "           }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "\n",
    "class FCT_Body(nn.Module):\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        b_attent_body = [2, 2, 2, 2, 2]\n",
    "        filters = [64, 128, 64, 32, 16, 8] \n",
    "        # number of blocks used in the model\n",
    "        blocks = len(b_attent_body)\n",
    "\n",
    "        stochastic_depth_rate = 0.0\n",
    "\n",
    "        #probability for each block\n",
    "        dpr = [x for x in np.linspace(0, stochastic_depth_rate, blocks)]\n",
    "\n",
    "\n",
    "        # model\n",
    "        self.block_5 = Block_encoder_bottleneck(\"bottleneck\", filters[0], filters[1], b_attent_body[0], dpr[0])\n",
    "        self.block_6 = Block_decoder(filters[1], filters[2], b_attent_body[1], dpr[1])\n",
    "        self.block_7 = Block_decoder(filters[2], filters[3], b_attent_body[2], dpr[2])\n",
    "        self.block_8 = Block_decoder(filters[3], filters[4], b_attent_body[3], dpr[3])\n",
    "        self.block_9 = Block_decoder(filters[4], filters[5], b_attent_body[4], dpr[4])\n",
    "    \n",
    "    def forward(self, skip1, skip2, skip3, skip4):\n",
    "        \n",
    "        x = self.block_5(skip4)\n",
    "        print(f\"Block 5 out -> {list(x.size())}\")\n",
    "        x = self.block_6(x, skip4)\n",
    "        print(f\"Block 6 out -> {list(x.size())}\")\n",
    "        x = self.block_7(x, skip3)\n",
    "        print(f\"Block 7 out -> {list(x.size())}\")\n",
    "        skip7 = x\n",
    "        x = self.block_8(x, skip2)\n",
    "        print(f\"Block 8 out -> {list(x.size())}\")\n",
    "        skip8 = x\n",
    "        x = self.block_9(x, skip1)\n",
    "        print(f\"Block 9 out -> {list(x.size())}\")\n",
    "        skip9 = x\n",
    "\n",
    "        return {\n",
    "        #     \"skip7\": skip7.cpu().detach().numpy(), \n",
    "        #     \"skip8\": skip8.cpu().detach().numpy(), \n",
    "            \"skip9\": skip9.cpu().detach().numpy(),\n",
    "           }\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FCT_Tail(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        filters = [32, 16, 8] \n",
    "        # number of blocks used in the model\n",
    "\n",
    "        # self.ds7 = DS_out(filters[0], 1)\n",
    "        # self.ds8 = DS_out(filters[1], 1)\n",
    "        # self.ds9 = DS_out(filters[2], 1)\n",
    "        self.ds10 = DS_out(filters[2], 1)\n",
    "    \n",
    "    def forward(self, # skip7, skip8, skip9):\n",
    "                skip9):\n",
    "        \n",
    "        # out7 = self.ds7(skip7)\n",
    "        # print(f\"DS 7 out -> {list(out7.size())}\")\n",
    "        # out8 = self.ds8(skip8)\n",
    "        # print(f\"DS 8 out -> {list(out8.size())}\")\n",
    "        # out9 = self.ds9(skip9)\n",
    "        # print(f\"DS 9 out -> {list(out9.size())}\")\n",
    "        out10 = self.ds10(skip9)\n",
    "        print(f\"DS 10 out -> {list(out10.size())}\")\n",
    "\n",
    "        return out10\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDC_2D(Dataset):\n",
    "    def __init__(self, source, ind, Transform=None):\n",
    "        # basic transforms\n",
    "        self.loader = mt.LoadImaged(keys=[\"image\", \"mask\"])\n",
    "        self.add_channel = mt.EnsureChannelFirstd(keys=[\"image\", \"mask\"])\n",
    "        self.spatial_pad = mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\")\n",
    "        self.spacing = mt.Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.25, 1.25, -1.0), mode=(\"nearest\", \"nearest\"))\n",
    "        # index\n",
    "        self.ind = ind\n",
    "        # transform\n",
    "        if Transform is not None:\n",
    "            self.transform = Transform\n",
    "        else:\n",
    "            self.transform = mt.Compose([\n",
    "                mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\"),\n",
    "                mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False)\n",
    "            ])\n",
    "\n",
    "        # take the images\n",
    "        source = Path(source)\n",
    "        # dirs = os.listdir(str(source))  # stores patient name\n",
    "        all_data_ed = []\n",
    "        all_data_ed_mask = []\n",
    "        all_data_es = []\n",
    "        all_data_es_mask = []\n",
    "        for filenames in source.iterdir():\n",
    "            if filenames.is_dir():\n",
    "                # patient_path = Path(str(source), filenames)  # individual patient path\n",
    "                patient_info = str(filenames / \"Info.cfg\")  # patient information\n",
    "                file = open(patient_info, 'r').readlines()\n",
    "                ED_frame = int(file[0].split(\":\")[1])\n",
    "                ES_frame = int(file[1].split(\":\")[1])\n",
    "                ED = (filenames / f\"{filenames.name}_frame{ED_frame:02d}.nii.gz\")\n",
    "                ES = (filenames / f\"{filenames.name}_frame{ES_frame:02d}.nii.gz\")\n",
    "                ED_gt = (filenames / f\"{filenames.name}_frame{ED_frame:02d}_gt.nii.gz\")\n",
    "                ES_gt = (filenames / f\"{filenames.name}_frame{ES_frame:02d}_gt.nii.gz\")\n",
    "                all_data_ed.append(ED)\n",
    "                all_data_ed_mask.append(ED_gt)\n",
    "                all_data_es.append(ES)\n",
    "                all_data_es_mask.append(ES_gt)\n",
    "\n",
    "        if self.ind is not None:\n",
    "            all_data_ed = [all_data_ed[i] for i in self.ind]\n",
    "            all_data_ed_mask = [all_data_ed_mask[i] for i in self.ind]\n",
    "            all_data_es = [all_data_es[i] for i in self.ind]\n",
    "            all_data_es_mask = [all_data_es_mask[i] for i in self.ind]\n",
    "\n",
    "        self.data = [all_data_ed, all_data_ed_mask, all_data_es, all_data_es_mask]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ED_img, ED_mask, ES_img, ES_mask = self.data[0][idx], self.data[1][idx], self.data[2][idx], self.data[3][idx]\n",
    "        # data dict\n",
    "        ED_data_dict = {\"image\": ED_img,\n",
    "                        \"mask\": ED_mask}\n",
    "        ES_data_dict = {\"image\": ES_img,\n",
    "                        \"mask\": ES_mask}\n",
    "        # instead of returning both ED and ES, I have to return just a random choice between ED and ES(image and mask)\n",
    "        datalist = [ED_data_dict, ES_data_dict]\n",
    "        data_return = np.random.choice(datalist)\n",
    "        data_return = self.loader(data_return)\n",
    "        data_return = self.add_channel(data_return)\n",
    "        data_return = self.spacing(data_return)\n",
    "        data_return[\"image\"] = normalize(data_return[\"image\"])\n",
    "        num_slice = data_return[\"image\"].shape[3]\n",
    "        random_slice = random.randint(0, num_slice - 1)\n",
    "        data_return[\"image\"] = data_return[\"image\"][:, :, :, random_slice]\n",
    "        data_return[\"image\"] = normalize(data_return[\"image\"])\n",
    "        data_return[\"mask\"] = data_return[\"mask\"][:, :, :, random_slice]\n",
    "        data_return = self.transform(data_return)\n",
    "        return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loader_ACDC(train_index, data_path=r\"../dataset/train_rosfl\", transform=None):\n",
    "    train_loader = ACDC_2D(source=data_path, Transform=transform, ind=train_index)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def val_loader_ACDC(val_index, data_path=r\"../dataset/train_rosfl\", transform=None):\n",
    "    val_loader = ACDC_2D(source=data_path, Transform=transform, ind=val_index)\n",
    "    return val_loader\n",
    "\n",
    "\n",
    "def test_loader_ACDC(test_index, data_path=r\"../dataset/testing\", transform=None):\n",
    "    test_loader = ACDC_2D(source=data_path, Transform=transform, ind=test_index)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" To test if the dataloader works \"\"\"\n",
    "\n",
    "train_compose = mt.Compose(\n",
    "    [mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\"),\n",
    "     mt.RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=crop_shape, random_center=True, random_size=False),\n",
    "     mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "     ]\n",
    ")\n",
    "\n",
    "val_compose = mt.Compose(\n",
    "    [\n",
    "        mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\"),\n",
    "        mt.RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=crop_shape, random_center=True, random_size=False),\n",
    "        mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_compose = mt.Compose(\n",
    "    [\n",
    "        mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\"),\n",
    "        mt.RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=crop_shape, random_center=True, random_size=False),\n",
    "        mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "concatenated_dataset = train_loader_ACDC(transform=None, train_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Fold 1 --------------------------\n",
      "train from here 20\n",
      "val from here 20\n",
      "-------------------------- Fold 2 --------------------------\n",
      "train from here 20\n",
      "val from here 20\n",
      "-------------------------- Fold 3 --------------------------\n",
      "train from here 20\n",
      "val from here 20\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(concatenated_dataset)))):\n",
    "\n",
    "    print(\"--------------------------\", \"Fold\", fold + 1, \"--------------------------\")\n",
    "\n",
    "    # training dataset\n",
    "    training_data = DataLoader(train_loader_ACDC(transform=train_compose, train_index=train_idx), batch_size=2,\n",
    "                               shuffle=False)\n",
    "    print(\"train from here\", len(training_data))\n",
    "    # for dic in training_data:\n",
    "    #     images = dic[\"image\"]\n",
    "    #     masks = dic[\"mask\"]\n",
    "    #     print(images.shape, masks.shape)\n",
    "    #     image, label = dic[\"image\"], dic[\"mask\"]\n",
    "    #     plt.figure(\"visualise\", (8, 4))\n",
    "    #     plt.subplot(1, 2, 1)\n",
    "    #     plt.title(\"image\")\n",
    "    #     plt.imshow(image[0, 0, :, :], cmap=\"gray\")\n",
    "    #     plt.subplot(1, 2, 2)\n",
    "    #     plt.title(\"mask\")\n",
    "    #     plt.imshow(label[0, 0, :, :], cmap=\"gray\")\n",
    "    #     plt.show()\n",
    "    #     break\n",
    "\n",
    "    # validation dataset\n",
    "    validation_data = DataLoader(val_loader_ACDC(transform=val_compose, val_index=val_idx), batch_size=1,\n",
    "                                 shuffle=False)\n",
    "    print(\"val from here\", len(validation_data))\n",
    "    # for dic in validation_data:\n",
    "    #     images = dic[\"image\"]\n",
    "    #     masks = dic[\"mask\"]\n",
    "    #     print(images.shape, masks.shape)\n",
    "    #     image, label = dic[\"image\"], dic[\"mask\"]\n",
    "    #     plt.figure(\"visualise\", (8, 4))\n",
    "    #     plt.subplot(1, 2, 1)\n",
    "    #     plt.title(\"image\")\n",
    "    #     plt.imshow(image[0, 0, :, :], cmap=\"gray\")\n",
    "    #     plt.subplot(1, 2, 2)\n",
    "    #     plt.title(\"mask\")\n",
    "    #     plt.imshow(label[0, 0, :, :], cmap=\"gray\")\n",
    "    #     plt.show()\n",
    "    #     break\n",
    "\n",
    "    # test dataset\n",
    "    # ========================== TEST Data ===================\n",
    "    # test_data = DataLoader(test_loader_ACDC(transform=test_compose, test_index=None), batch_size=1, shuffle=False)\n",
    "    # ========================== TEST Data ===================\n",
    "    # print(\"test from here\")\n",
    "    # for dic in test_data:\n",
    "    #     images = dic[\"image\"]\n",
    "    #     masks = dic[\"mask\"]\n",
    "    #     print(images.shape, masks.shape)\n",
    "    #     image, label = dic[\"image\"], dic[\"mask\"]\n",
    "    #     plt.figure(\"visualise\", (8, 4))\n",
    "    #     plt.subplot(1, 2, 1)\n",
    "    #     plt.title(\"image\")\n",
    "    #     plt.imshow(image[0, 0, :, :], cmap=\"gray\")\n",
    "    #     plt.subplot(1, 2, 2)\n",
    "    #     plt.title(\"mask\")\n",
    "    #     plt.imshow(label[0, 0, :, :], cmap=\"gray\")\n",
    "    #     plt.show()\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses.dice import GeneralizedDiceLoss\n",
    "\n",
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    Initialize the weights\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "dic_loss_fn = GeneralizedDiceLoss(to_onehot_y=True, softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ....\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "#                                HEAD\n",
    "# =======================================================================\n",
    "\n",
    "model_head = FCT_Head()\n",
    "model_head.apply(init_weights)\n",
    "\n",
    "optimizer_head = torch.optim.Adam(model_head.parameters(), lr=dict_args['lr'],weight_decay=dict_args['decay'])\n",
    "\n",
    "scheduler_head = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer_head,\n",
    "            mode='min',\n",
    "            factor=dict_args['lr_factor'],\n",
    "            verbose=True,\n",
    "            threshold=1e-6,\n",
    "            patience=10,\n",
    "            min_lr=dict_args['min_lr'])\n",
    "\n",
    "model_head.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# =======================================================================\n",
    "#                                BODY\n",
    "# =======================================================================\n",
    "\n",
    "model_body = FCT_Body()\n",
    "model_body.apply(init_weights)\n",
    "\n",
    "optimizer_body = torch.optim.AdamW(model_body.parameters(), lr=dict_args['lr'],weight_decay=dict_args['decay'])\n",
    "\n",
    "scheduler_body = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer_body,\n",
    "            mode='min',\n",
    "            factor=dict_args['lr_factor'],\n",
    "            verbose=True,\n",
    "            threshold=1e-6,\n",
    "            patience=10,\n",
    "            min_lr=dict_args['min_lr'])\n",
    "\n",
    "model_body.to(device)\n",
    "\n",
    "# =======================================================================\n",
    "#                                TAIL\n",
    "# =======================================================================\n",
    "\n",
    "model_tail = FCT_Tail()\n",
    "model_tail.apply(init_weights)\n",
    "\n",
    "optimizer_tail = torch.optim.AdamW(model_tail.parameters(), lr=dict_args['lr'],weight_decay=dict_args['decay'])\n",
    "\n",
    "scheduler_tail = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer_tail,\n",
    "            mode='min',\n",
    "            factor=dict_args['lr_factor'],\n",
    "            verbose=True,\n",
    "            threshold=1e-6,\n",
    "            patience=10,\n",
    "            min_lr=dict_args['min_lr'])\n",
    "\n",
    "model_tail.to(device)\n",
    "\n",
    "print(\"Initialized ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  0\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:53,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:05<00:46,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  2\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:07<00:43,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  3\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:10<00:41,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  4\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:12<00:38,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  5\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:15<00:35,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  6\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:17<00:32,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  7\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:20<00:30,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  8\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:23<00:27,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:25<00:25,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:28<00:22,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:30<00:20,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  12\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:33<00:17,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  13\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:35<00:14,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  14\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:37<00:12,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  15\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:40<00:10,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:43<00:07,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  17\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:45<00:05,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 4 out -> [2, 64, 14, 14]\n",
      "index value is  18\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:48<00:02,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index value is  19\n",
      "Block 1 out -> [2, 8, 112, 112]\n",
      "Block 2 out -> [2, 16, 56, 56]\n",
      "Block 3 out -> [2, 32, 28, 28]\n",
      "Block 4 out -> [2, 64, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:50<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "model_head.train()\n",
    "\n",
    "try:\n",
    "    fh5_head = h5py.File('params_and_grads/h5_head_values.hdf5', 'w') \n",
    "    fh5_label = h5py.File('params_and_grads/h5_train_label.hdf5', 'w')\n",
    "    for index, train_dict in tqdm(enumerate(training_data), total=len(training_data)):\n",
    "        print(\"index value is \", index)\n",
    "        X_train = train_dict[\"image\"]\n",
    "        y_train = train_dict[\"mask\"]\n",
    "        X_train = X_train.to(device)\n",
    "\n",
    "        layer_data = model_head(X_train)\n",
    "\n",
    "        grp_head = fh5_head.create_group(f'IterKey_{index}')\n",
    "        for k, v in layer_data.items():\n",
    "            grp_head.create_dataset(k, data=v)\n",
    "        \n",
    "        grp_label = fh5_label.create_group(f'IterKey_{index}')\n",
    "        grp_label.create_dataset(\"tlabel\", data=y_train.cpu().detach().numpy())\n",
    "except Exception as ex:\n",
    "    import traceback\n",
    "    print(\"+=\" * 25)\n",
    "    print(\"Error encountered as :\", ex)\n",
    "    print(\"+=\" * 25)\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    fh5_head.close()\n",
    "    fh5_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:42,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:39,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:37,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:08<00:35,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:10<00:32,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:13<00:30,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:15<00:27,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:17<00:25,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:19<00:23,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:21<00:21,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:23<00:19,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:26<00:17,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:28<00:15,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:30<00:12,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:32<00:10,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:34<00:08,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:36<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:38<00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:41<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n",
      "Block 5 out -> [2, 128, 7, 7]\n",
      "Block 6 out -> [2, 64, 14, 14]\n",
      "Block 7 out -> [2, 32, 28, 28]\n",
      "Block 8 out -> [2, 16, 56, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9 out -> [2, 8, 112, 112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_body.train()\n",
    "\n",
    "fh5_body = h5py.File('params_and_grads/h5_body_values.hdf5', 'w')\n",
    "\n",
    "try:\n",
    "    with h5py.File('params_and_grads/h5_head_values.hdf5', 'r') as f_head:\n",
    "        for key, grp in tqdm(f_head.items(), total=len(f_head)):\n",
    "            skip_1 = torch.from_numpy(grp['skip1'][:]).to(device)\n",
    "            skip_2 = torch.from_numpy(grp['skip2'][:]).to(device)\n",
    "            skip_3 = torch.from_numpy(grp['skip3'][:]).to(device)     \n",
    "            skip_4 = torch.from_numpy(grp['skip4'][:]).to(device)\n",
    "\n",
    "            bd_layer_data = model_body(skip_1, skip_2, skip_3, skip_4)\n",
    "\n",
    "            bgrp = fh5_body.create_group(key)\n",
    "            for k,v in bd_layer_data.items():\n",
    "                bgrp.create_dataset(k, data=v)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    fh5_body.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n",
      "DS 10 out -> [2, 1, 224, 224]\n"
     ]
    }
   ],
   "source": [
    "model_tail.train()\n",
    "train_loss_list = []\n",
    "grads_dict = {}\n",
    "abs_grads_dict = {}\n",
    "\n",
    "\n",
    "fh5_body = h5py.File('params_and_grads/h5_body_values.hdf5', 'r')\n",
    "fh5_label = h5py.File('params_and_grads/h5_train_label.hdf5', 'r')\n",
    "\n",
    "try:\n",
    "    for (key, grp), (lkey, lgrp) in zip(fh5_body.items(), fh5_label.items()):\n",
    "\n",
    "        if str(key) != str(lkey):\n",
    "            print(f\"Not the same key tail:: {key} and label:: {lkey}, data could be different \")\n",
    "        \n",
    "        # skip_7 = torch.tensor(grp['skip7'][:], requires_grad=True).to(device)\n",
    "        # skip_8 = torch.tensor(grp['skip8'][:], requires_grad=True).to(device)\n",
    "        skip_9 = torch.tensor(grp['skip9'][:], requires_grad=True).to(device)\n",
    "        \n",
    "        y_mask = torch.from_numpy(lgrp['tlabel'][:]).to(device)\n",
    "\n",
    "        tl_output_data = model_tail(# skip_7, skip_8, \n",
    "            skip_9\n",
    "            )\n",
    "        \n",
    "        loss = loss_fn(tl_output_data, y_mask)\n",
    "        train_loss_list.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer_tail.step()\n",
    "\n",
    "except Exception as ex:\n",
    "    import traceback\n",
    "    print(\"+=\" * 25)\n",
    "    print(\"Error encountered as :\", ex)\n",
    "    print(\"+=\" * 25)\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    fh5_body.close()\n",
    "    fh5_label.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads_dict : \n",
      " {'ds10.layernorm.weight': [tensor([ 0.4994,  0.1910, -0.0348,  0.3572,  0.2148,  0.0237,  0.0675,  0.8519])], 'ds10.layernorm.bias': [tensor([ 0.2581, -0.3783,  0.1922, -0.5930, -0.2444,  0.1632,  0.1884,  0.4015])], 'ds10.conv1.0.weight': [tensor([[[[ 1.9865e-01,  1.4809e-01,  1.5886e-01],\n",
      "          [ 2.2671e-01,  1.7270e-01,  1.9018e-01],\n",
      "          [ 8.6830e-02,  4.7224e-02,  1.0767e-01]],\n",
      "\n",
      "         [[ 1.4213e-02,  2.9643e-02, -1.2107e-02],\n",
      "          [-2.3407e-02,  1.8475e-02, -8.3898e-03],\n",
      "          [ 4.5466e-02,  5.7744e-02, -1.2270e-02]],\n",
      "\n",
      "         [[-8.5668e-02, -8.7973e-02, -8.0554e-02],\n",
      "          [-9.0638e-02, -1.0873e-01, -1.0334e-01],\n",
      "          [-1.0130e-01, -1.0615e-01, -8.9239e-02]],\n",
      "\n",
      "         [[-1.0082e-01, -9.3206e-02, -6.5363e-02],\n",
      "          [-1.0830e-01, -1.0939e-01, -8.9939e-02],\n",
      "          [-8.0069e-02, -7.0748e-02, -5.1862e-02]],\n",
      "\n",
      "         [[-9.6369e-02, -9.8693e-02, -1.0131e-01],\n",
      "          [-8.6684e-02, -9.7869e-02, -1.0381e-01],\n",
      "          [-1.0483e-01, -1.0923e-01, -1.0789e-01]],\n",
      "\n",
      "         [[-5.0360e-02, -7.6307e-02, -1.0130e-01],\n",
      "          [-8.6562e-02, -9.4801e-02, -9.2866e-02],\n",
      "          [-5.8725e-02, -5.2677e-02, -4.6541e-02]],\n",
      "\n",
      "         [[-9.3958e-02, -4.8697e-02, -3.8521e-02],\n",
      "          [-3.2731e-02,  1.0831e-02, -1.9286e-02],\n",
      "          [-9.0683e-02, -7.8541e-02, -1.0579e-01]],\n",
      "\n",
      "         [[ 2.1088e-01,  2.2374e-01,  2.3740e-01],\n",
      "          [ 1.9857e-01,  2.0556e-01,  2.2464e-01],\n",
      "          [ 3.0004e-01,  3.0908e-01,  3.0325e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0844e-01,  2.4845e-01,  2.7128e-01],\n",
      "          [ 2.0412e-01,  2.1807e-01,  2.4526e-01],\n",
      "          [ 2.2036e-01,  1.9469e-01,  2.0353e-01]],\n",
      "\n",
      "         [[-3.3928e-02, -3.1858e-02, -3.3741e-02],\n",
      "          [-1.1216e-02, -4.0216e-02, -6.0707e-02],\n",
      "          [-1.0803e-02, -4.1611e-02, -6.4016e-02]],\n",
      "\n",
      "         [[-9.5717e-02, -8.9765e-02, -9.2807e-02],\n",
      "          [-1.0410e-01, -1.0700e-01, -1.0014e-01],\n",
      "          [-1.0242e-01, -1.1146e-01, -1.0742e-01]],\n",
      "\n",
      "         [[-7.8758e-02, -7.5024e-02, -7.7061e-02],\n",
      "          [-7.2274e-02, -7.5851e-02, -8.2411e-02],\n",
      "          [-7.4599e-02, -8.0577e-02, -8.6801e-02]],\n",
      "\n",
      "         [[-1.1828e-01, -1.1875e-01, -1.1787e-01],\n",
      "          [-1.1565e-01, -1.1790e-01, -1.1896e-01],\n",
      "          [-1.1196e-01, -1.1636e-01, -1.2109e-01]],\n",
      "\n",
      "         [[-6.4675e-02, -7.6136e-02, -8.8763e-02],\n",
      "          [-6.4207e-02, -6.6164e-02, -7.4713e-02],\n",
      "          [-7.2986e-02, -5.9123e-02, -5.1296e-02]],\n",
      "\n",
      "         [[-8.8162e-02, -7.7668e-02, -7.4318e-02],\n",
      "          [-8.8699e-02, -5.9860e-02, -5.1360e-02],\n",
      "          [-8.9549e-02, -6.4230e-02, -5.7646e-02]],\n",
      "\n",
      "         [[ 2.6920e-01,  2.1858e-01,  2.1095e-01],\n",
      "          [ 2.4952e-01,  2.4700e-01,  2.4158e-01],\n",
      "          [ 2.3920e-01,  2.7684e-01,  2.8361e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2160e-02,  3.6469e-02,  4.8298e-02],\n",
      "          [ 3.9517e-02,  3.5530e-02,  4.3557e-02],\n",
      "          [ 6.8364e-02,  6.6139e-02,  5.9386e-02]],\n",
      "\n",
      "         [[-2.6583e-02, -1.7202e-02, -1.5323e-04],\n",
      "          [-3.0526e-02, -1.1083e-02,  5.0209e-03],\n",
      "          [-1.8701e-02, -4.5317e-03, -3.4727e-03]],\n",
      "\n",
      "         [[-2.0971e-02, -2.4176e-02, -2.7203e-02],\n",
      "          [-2.2386e-02, -2.0510e-02, -2.2635e-02],\n",
      "          [-3.0507e-02, -2.4983e-02, -2.3554e-02]],\n",
      "\n",
      "         [[-1.2856e-02, -1.2285e-02, -1.6918e-02],\n",
      "          [-1.4068e-02, -1.2518e-02, -1.7693e-02],\n",
      "          [-2.2779e-02, -2.3928e-02, -2.3644e-02]],\n",
      "\n",
      "         [[-3.8933e-02, -3.8500e-02, -3.5639e-02],\n",
      "          [-3.8136e-02, -3.9828e-02, -3.7412e-02],\n",
      "          [-3.7038e-02, -3.7543e-02, -3.6206e-02]],\n",
      "\n",
      "         [[-2.2162e-03, -1.2453e-02, -2.8569e-02],\n",
      "          [-1.4293e-03, -7.9306e-03, -2.4362e-02],\n",
      "          [-1.0465e-02, -1.0722e-02, -1.5614e-02]],\n",
      "\n",
      "         [[-1.9821e-02, -1.8904e-02, -2.6752e-02],\n",
      "          [-1.5997e-02, -1.5717e-02, -2.3709e-02],\n",
      "          [-2.4565e-02, -2.5958e-02, -2.8041e-02]],\n",
      "\n",
      "         [[ 8.9358e-02,  8.6859e-02,  8.6104e-02],\n",
      "          [ 8.3217e-02,  7.1818e-02,  7.6374e-02],\n",
      "          [ 7.5468e-02,  6.1010e-02,  7.0496e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2440e-01,  5.3160e-01,  5.4946e-01],\n",
      "          [ 5.9602e-01,  5.7484e-01,  5.7341e-01],\n",
      "          [ 5.6724e-01,  5.5401e-01,  5.4132e-01]],\n",
      "\n",
      "         [[-1.0150e-01, -8.5130e-02, -5.5889e-02],\n",
      "          [-1.2093e-01, -1.0317e-01, -7.8893e-02],\n",
      "          [-8.9666e-02, -8.3962e-02, -7.2627e-02]],\n",
      "\n",
      "         [[-2.5542e-01, -2.5609e-01, -2.6646e-01],\n",
      "          [-2.6443e-01, -2.4977e-01, -2.6662e-01],\n",
      "          [-2.8302e-01, -2.5716e-01, -2.6705e-01]],\n",
      "\n",
      "         [[-2.2135e-01, -2.2024e-01, -2.2172e-01],\n",
      "          [-2.2446e-01, -2.3849e-01, -2.5197e-01],\n",
      "          [-2.0959e-01, -2.4122e-01, -2.6314e-01]],\n",
      "\n",
      "         [[-3.2837e-01, -3.2989e-01, -3.3433e-01],\n",
      "          [-3.2790e-01, -3.1927e-01, -3.2500e-01],\n",
      "          [-3.3880e-01, -3.2454e-01, -3.2731e-01]],\n",
      "\n",
      "         [[-1.9062e-01, -1.6845e-01, -1.5992e-01],\n",
      "          [-2.0677e-01, -1.9134e-01, -1.6610e-01],\n",
      "          [-2.0002e-01, -1.9593e-01, -1.7992e-01]],\n",
      "\n",
      "         [[-2.5315e-01, -2.7122e-01, -2.8160e-01],\n",
      "          [-2.5818e-01, -3.0080e-01, -3.0346e-01],\n",
      "          [-2.8566e-01, -3.3439e-01, -3.2890e-01]],\n",
      "\n",
      "         [[ 8.2175e-01,  7.9461e-01,  7.6499e-01],\n",
      "          [ 8.0241e-01,  8.2273e-01,  8.1303e-01],\n",
      "          [ 8.3468e-01,  8.7761e-01,  8.9224e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8450e-03,  1.4202e-02,  1.6874e-02],\n",
      "          [ 3.1669e-03,  8.8563e-03,  1.2156e-02],\n",
      "          [ 5.5739e-03,  9.1905e-03,  1.0079e-02]],\n",
      "\n",
      "         [[-3.2462e-03, -5.5594e-03, -4.8830e-03],\n",
      "          [ 1.8929e-03, -2.4510e-03, -4.9771e-03],\n",
      "          [ 3.5944e-03, -2.6571e-03, -5.9931e-03]],\n",
      "\n",
      "         [[-2.1042e-03, -6.2853e-03, -7.7133e-03],\n",
      "          [-3.1207e-03, -6.6050e-03, -7.5923e-03],\n",
      "          [-2.7483e-03, -6.0073e-03, -6.9804e-03]],\n",
      "\n",
      "         [[ 1.7191e-05, -3.4168e-03, -4.2028e-03],\n",
      "          [ 9.8754e-04, -1.7348e-03, -3.0276e-03],\n",
      "          [ 7.1694e-04, -1.4722e-03, -3.0202e-03]],\n",
      "\n",
      "         [[-4.3174e-03, -8.1898e-03, -8.7919e-03],\n",
      "          [-4.0526e-03, -8.6100e-03, -9.1597e-03],\n",
      "          [-4.5849e-03, -8.6125e-03, -8.9621e-03]],\n",
      "\n",
      "         [[-2.0850e-03, -3.1012e-03, -3.9476e-03],\n",
      "          [-2.7238e-03, -1.7144e-03, -1.3003e-03],\n",
      "          [-2.2337e-03, -4.9336e-04, -1.7316e-04]],\n",
      "\n",
      "         [[ 3.2202e-03,  2.2614e-03,  1.8632e-03],\n",
      "          [ 2.4392e-03, -8.9776e-04, -2.8567e-03],\n",
      "          [-1.1681e-03, -3.4221e-03, -3.9498e-03]],\n",
      "\n",
      "         [[ 2.6776e-03,  1.0103e-02,  1.0791e-02],\n",
      "          [ 1.3704e-03,  1.3155e-02,  1.6780e-02],\n",
      "          [ 7.9747e-04,  1.3475e-02,  1.9028e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1324e-01,  3.2433e-01,  3.1529e-01],\n",
      "          [ 3.4212e-01,  3.7386e-01,  3.4135e-01],\n",
      "          [ 3.4472e-01,  4.0443e-01,  3.5231e-01]],\n",
      "\n",
      "         [[-4.9419e-02, -7.5073e-02, -5.6087e-02],\n",
      "          [-5.3499e-02, -9.6072e-02, -6.3009e-02],\n",
      "          [-4.2964e-02, -1.0683e-01, -6.6339e-02]],\n",
      "\n",
      "         [[-1.5111e-01, -1.2631e-01, -1.3823e-01],\n",
      "          [-1.5252e-01, -1.2675e-01, -1.3984e-01],\n",
      "          [-1.5925e-01, -1.3813e-01, -1.4560e-01]],\n",
      "\n",
      "         [[-1.3729e-01, -1.2769e-01, -1.3822e-01],\n",
      "          [-1.3438e-01, -1.2809e-01, -1.5247e-01],\n",
      "          [-1.3087e-01, -1.3744e-01, -1.5741e-01]],\n",
      "\n",
      "         [[-2.0239e-01, -1.9008e-01, -1.9225e-01],\n",
      "          [-2.0345e-01, -1.8559e-01, -1.8613e-01],\n",
      "          [-2.0617e-01, -1.8720e-01, -1.9179e-01]],\n",
      "\n",
      "         [[-1.2443e-01, -1.1786e-01, -9.9358e-02],\n",
      "          [-1.2715e-01, -1.1900e-01, -1.0551e-01],\n",
      "          [-1.3103e-01, -1.1178e-01, -1.1018e-01]],\n",
      "\n",
      "         [[-1.6737e-01, -1.9752e-01, -1.9932e-01],\n",
      "          [-1.4666e-01, -1.8109e-01, -1.9181e-01],\n",
      "          [-1.5747e-01, -1.8997e-01, -1.8993e-01]],\n",
      "\n",
      "         [[ 5.1317e-01,  5.0486e-01,  5.0288e-01],\n",
      "          [ 4.7013e-01,  4.5760e-01,  4.9196e-01],\n",
      "          [ 4.7779e-01,  4.6204e-01,  5.0342e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5913e-01,  1.3692e-01,  1.4786e-01],\n",
      "          [ 1.5575e-01,  1.3557e-01,  1.5222e-01],\n",
      "          [ 1.7556e-01,  1.3354e-01,  1.3063e-01]],\n",
      "\n",
      "         [[-1.9201e-02, -1.7121e-02, -1.5009e-02],\n",
      "          [-4.4922e-02, -5.7089e-02, -4.6560e-02],\n",
      "          [-5.6833e-02, -5.0532e-02, -1.9647e-02]],\n",
      "\n",
      "         [[-1.0248e-01, -1.0875e-01, -1.1780e-01],\n",
      "          [-9.2136e-02, -9.9737e-02, -1.1077e-01],\n",
      "          [-1.0327e-01, -1.0699e-01, -1.0618e-01]],\n",
      "\n",
      "         [[-9.3113e-02, -7.5199e-02, -5.5293e-02],\n",
      "          [-9.8364e-02, -9.4379e-02, -8.0651e-02],\n",
      "          [-9.6253e-02, -9.8360e-02, -1.0122e-01]],\n",
      "\n",
      "         [[-1.4090e-01, -1.5344e-01, -1.5426e-01],\n",
      "          [-1.4319e-01, -1.4818e-01, -1.4841e-01],\n",
      "          [-1.4696e-01, -1.4499e-01, -1.4061e-01]],\n",
      "\n",
      "         [[-6.8136e-02, -5.4243e-02, -6.5893e-02],\n",
      "          [-6.4224e-02, -6.0221e-02, -7.3838e-02],\n",
      "          [-5.7126e-02, -6.3706e-02, -7.8848e-02]],\n",
      "\n",
      "         [[-9.4120e-02, -8.1675e-02, -7.4532e-02],\n",
      "          [-6.9640e-02, -5.7443e-02, -5.3541e-02],\n",
      "          [-5.0856e-02, -5.5463e-02, -7.0773e-02]],\n",
      "\n",
      "         [[ 3.5890e-01,  3.5355e-01,  3.3494e-01],\n",
      "          [ 3.5685e-01,  3.8158e-01,  3.6159e-01],\n",
      "          [ 3.3583e-01,  3.8656e-01,  3.8663e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3211e-01,  2.2803e-01,  1.7731e-01],\n",
      "          [ 1.7475e-01,  1.8172e-01,  2.0792e-01],\n",
      "          [ 1.5401e-01,  1.3465e-01,  2.1937e-01]],\n",
      "\n",
      "         [[-1.7223e-02, -3.5451e-02, -1.9735e-02],\n",
      "          [ 4.2816e-04, -3.0366e-02, -3.9943e-02],\n",
      "          [ 9.6512e-04, -9.3163e-03, -4.6348e-02]],\n",
      "\n",
      "         [[-9.4580e-02, -9.3927e-02, -9.5819e-02],\n",
      "          [-9.9309e-02, -8.9564e-02, -9.3407e-02],\n",
      "          [-1.1274e-01, -1.0142e-01, -9.0570e-02]],\n",
      "\n",
      "         [[-9.5082e-02, -9.9393e-02, -8.7844e-02],\n",
      "          [-9.7510e-02, -9.4353e-02, -8.2761e-02],\n",
      "          [-9.7667e-02, -8.8453e-02, -7.4640e-02]],\n",
      "\n",
      "         [[-1.2212e-01, -1.1222e-01, -1.1391e-01],\n",
      "          [-1.2529e-01, -1.1993e-01, -1.1403e-01],\n",
      "          [-1.2405e-01, -1.2696e-01, -1.2019e-01]],\n",
      "\n",
      "         [[-8.0277e-02, -8.2090e-02, -8.5250e-02],\n",
      "          [-8.0426e-02, -8.4717e-02, -9.2205e-02],\n",
      "          [-7.7029e-02, -7.7159e-02, -8.3157e-02]],\n",
      "\n",
      "         [[-1.0374e-01, -9.6147e-02, -9.7934e-02],\n",
      "          [-9.0403e-02, -9.1010e-02, -1.0022e-01],\n",
      "          [-7.1587e-02, -7.6521e-02, -1.0559e-01]],\n",
      "\n",
      "         [[ 2.7859e-01,  2.8923e-01,  3.2092e-01],\n",
      "          [ 3.1499e-01,  3.2629e-01,  3.1282e-01],\n",
      "          [ 3.2540e-01,  3.4323e-01,  2.9982e-01]]]])], 'ds10.conv1.0.bias': [tensor([0.1290, 0.1548, 0.0482, 0.4670, 0.0099, 0.2634, 0.1988, 0.1646])], 'ds10.conv2.0.weight': [tensor([[[[ 3.0945e-01,  2.1515e-01,  2.3593e-01],\n",
      "          [ 3.2346e-01,  2.0343e-01,  2.7492e-01],\n",
      "          [ 3.5199e-01,  2.6301e-01,  3.4544e-01]],\n",
      "\n",
      "         [[ 3.0800e-03,  7.7414e-03,  1.0095e-02],\n",
      "          [ 7.4642e-03,  1.1205e-02,  9.6172e-03],\n",
      "          [ 1.2815e-02,  1.6814e-02,  1.2891e-02]],\n",
      "\n",
      "         [[ 5.2779e-03,  4.4080e-03,  1.0787e-02],\n",
      "          [ 6.4016e-03,  7.3864e-03,  1.1382e-02],\n",
      "          [ 5.5409e-03,  7.3588e-03,  1.0129e-02]],\n",
      "\n",
      "         [[ 5.2243e-02,  5.9707e-02,  7.3695e-02],\n",
      "          [ 7.2736e-02,  7.8237e-02,  9.5356e-02],\n",
      "          [ 4.9141e-02,  5.8033e-02,  6.5680e-02]],\n",
      "\n",
      "         [[ 6.9123e-03,  9.0623e-03,  4.1270e-03],\n",
      "          [ 7.7207e-03,  9.5790e-03,  4.0825e-03],\n",
      "          [ 6.4665e-03,  7.5516e-03,  3.6405e-03]],\n",
      "\n",
      "         [[ 3.5462e-01,  4.2662e-01,  4.3518e-01],\n",
      "          [ 3.5384e-01,  4.5162e-01,  4.9646e-01],\n",
      "          [ 3.7537e-01,  4.5946e-01,  4.9711e-01]],\n",
      "\n",
      "         [[ 5.7653e-02,  5.1269e-02,  5.2813e-02],\n",
      "          [ 5.4998e-02,  5.4283e-02,  5.8315e-02],\n",
      "          [ 4.6351e-02,  4.8865e-02,  5.6120e-02]],\n",
      "\n",
      "         [[ 3.5815e-02,  1.6684e-02,  1.3329e-02],\n",
      "          [ 1.8191e-02,  2.2342e-02,  2.9904e-02],\n",
      "          [ 1.4904e-02,  3.3136e-02,  4.0526e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8815e-01,  6.6044e-01,  6.8030e-01],\n",
      "          [ 6.8619e-01,  6.5262e-01,  6.6864e-01],\n",
      "          [ 6.8562e-01,  6.6797e-01,  6.6894e-01]],\n",
      "\n",
      "         [[ 6.1644e-02,  5.5882e-02,  4.7353e-02],\n",
      "          [ 5.1492e-02,  4.4896e-02,  3.7128e-02],\n",
      "          [ 4.5685e-02,  3.7191e-02,  3.6981e-02]],\n",
      "\n",
      "         [[ 1.0441e-02,  9.2115e-03,  1.0330e-02],\n",
      "          [ 1.1359e-02,  1.1805e-02,  9.0726e-03],\n",
      "          [ 1.0338e-02,  9.5339e-03,  7.5003e-03]],\n",
      "\n",
      "         [[ 1.5220e-01,  1.6717e-01,  1.8638e-01],\n",
      "          [ 1.4642e-01,  1.5785e-01,  1.7077e-01],\n",
      "          [ 1.7615e-01,  1.7288e-01,  1.7883e-01]],\n",
      "\n",
      "         [[-3.2331e-03, -4.2142e-03, -3.1219e-03],\n",
      "          [-4.9357e-03, -5.4089e-03, -5.7772e-03],\n",
      "          [-4.9695e-03, -5.9667e-03, -4.5185e-03]],\n",
      "\n",
      "         [[ 8.5155e-01,  8.9974e-01,  8.9219e-01],\n",
      "          [ 8.1539e-01,  8.5328e-01,  8.6273e-01],\n",
      "          [ 8.3077e-01,  8.4881e-01,  8.4691e-01]],\n",
      "\n",
      "         [[-1.2439e-02, -1.8893e-02, -3.5384e-02],\n",
      "          [-3.8410e-02, -3.0521e-02, -3.5107e-02],\n",
      "          [-5.6023e-02, -5.1251e-02, -4.1616e-02]],\n",
      "\n",
      "         [[ 1.3878e-01,  1.2582e-01,  1.4075e-01],\n",
      "          [ 1.1755e-01,  1.0382e-01,  1.3209e-01],\n",
      "          [ 1.1655e-01,  9.6426e-02,  1.1609e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1656e-03,  3.1455e-03,  2.2357e-03],\n",
      "          [ 1.0797e-03,  1.0720e-03, -7.2101e-04],\n",
      "          [ 1.1007e-03,  6.8303e-04, -4.9420e-04]],\n",
      "\n",
      "         [[ 7.1211e-05, -2.7247e-04,  1.7064e-04],\n",
      "          [ 3.2424e-05, -4.7088e-04,  3.5298e-04],\n",
      "          [-7.2845e-05, -4.4948e-05,  1.9994e-04]],\n",
      "\n",
      "         [[ 2.4377e-04, -4.2160e-05, -2.5994e-04],\n",
      "          [ 5.0769e-04, -7.1945e-06, -3.3515e-04],\n",
      "          [ 6.9746e-05, -9.2423e-05, -1.6850e-04]],\n",
      "\n",
      "         [[ 3.2365e-04,  4.4943e-04,  2.9488e-04],\n",
      "          [-9.1758e-04, -1.3949e-03, -9.3369e-04],\n",
      "          [-9.3366e-05, -5.9762e-04, -9.6014e-05]],\n",
      "\n",
      "         [[ 1.3733e-04, -1.4669e-04,  1.0517e-04],\n",
      "          [ 1.2921e-04, -2.2398e-04, -2.1139e-04],\n",
      "          [ 1.4903e-04, -4.6539e-05,  8.9534e-07]],\n",
      "\n",
      "         [[ 1.4323e-03,  1.3258e-03,  1.9913e-03],\n",
      "          [ 1.4057e-04, -4.5470e-05,  6.3425e-04],\n",
      "          [-5.6157e-05, -7.4993e-04, -3.5030e-05]],\n",
      "\n",
      "         [[ 9.2694e-04,  4.8194e-04,  2.7876e-04],\n",
      "          [ 1.4023e-04,  2.2431e-04,  9.6494e-04],\n",
      "          [ 2.1366e-04,  2.9446e-04,  4.7517e-04]],\n",
      "\n",
      "         [[ 3.0068e-04,  3.6404e-04,  5.5591e-05],\n",
      "          [ 3.7914e-04,  5.1309e-04,  7.9664e-05],\n",
      "          [-1.5364e-06, -3.8784e-05,  6.7722e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1080e-01,  4.1193e-01,  3.9595e-01],\n",
      "          [ 3.3250e-01,  3.7517e-01,  3.6793e-01],\n",
      "          [ 3.5036e-01,  4.1149e-01,  3.6900e-01]],\n",
      "\n",
      "         [[ 3.7183e-02,  3.4636e-02,  2.6595e-02],\n",
      "          [ 3.4464e-02,  3.0572e-02,  1.8655e-02],\n",
      "          [ 2.3858e-02,  2.3725e-02,  2.5702e-02]],\n",
      "\n",
      "         [[ 4.6474e-03,  1.4958e-03,  1.3203e-03],\n",
      "          [ 7.6637e-03,  5.3917e-03,  1.7072e-03],\n",
      "          [ 9.5007e-03,  9.6738e-03,  6.5370e-03]],\n",
      "\n",
      "         [[ 9.0309e-02,  9.2017e-02,  9.9983e-02],\n",
      "          [ 7.2174e-02,  6.6948e-02,  6.9529e-02],\n",
      "          [ 9.6588e-02,  9.3176e-02,  7.7942e-02]],\n",
      "\n",
      "         [[-2.7612e-03, -3.3430e-03, -2.9302e-03],\n",
      "          [-2.5337e-03, -3.1498e-03, -3.3461e-03],\n",
      "          [-2.4977e-03, -2.3334e-03, -1.6737e-03]],\n",
      "\n",
      "         [[ 4.2071e-01,  4.5031e-01,  4.9732e-01],\n",
      "          [ 4.0639e-01,  3.9419e-01,  4.3824e-01],\n",
      "          [ 4.1621e-01,  3.7310e-01,  3.9490e-01]],\n",
      "\n",
      "         [[-3.1225e-02, -2.3268e-02, -2.1567e-02],\n",
      "          [-2.6662e-02, -2.1823e-02, -2.5664e-02],\n",
      "          [-2.4025e-02, -2.9442e-02, -3.7420e-02]],\n",
      "\n",
      "         [[ 8.4584e-02,  9.7314e-02,  8.8167e-02],\n",
      "          [ 7.0231e-02,  9.2419e-02,  8.9495e-02],\n",
      "          [ 6.1711e-02,  7.1806e-02,  7.4866e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4536e-01,  2.9924e-01,  3.2768e-01],\n",
      "          [ 2.9686e-01,  2.3362e-01,  2.4716e-01],\n",
      "          [ 2.2094e-01,  1.3713e-01,  1.7884e-01]],\n",
      "\n",
      "         [[ 3.6699e-02,  2.4096e-02,  2.8899e-02],\n",
      "          [ 3.8484e-02,  2.0617e-02,  1.5887e-02],\n",
      "          [ 2.6083e-02,  2.8192e-02,  1.2129e-02]],\n",
      "\n",
      "         [[-1.0839e-03,  3.8662e-03,  1.0021e-02],\n",
      "          [ 2.0227e-03, -2.3885e-04,  1.9262e-03],\n",
      "          [ 6.4133e-03,  4.1612e-03,  7.1133e-03]],\n",
      "\n",
      "         [[ 9.3478e-02,  1.1052e-01,  1.2868e-01],\n",
      "          [ 6.2472e-02,  7.0944e-02,  1.0322e-01],\n",
      "          [ 6.0517e-02,  5.2918e-02,  8.3033e-02]],\n",
      "\n",
      "         [[-4.5898e-03, -5.0318e-04, -9.1952e-04],\n",
      "          [-3.1840e-03, -3.9983e-04, -2.1509e-03],\n",
      "          [-2.9400e-03,  1.7650e-04, -1.7309e-03]],\n",
      "\n",
      "         [[ 3.4720e-01,  3.7091e-01,  3.2969e-01],\n",
      "          [ 3.1758e-01,  3.7297e-01,  3.4042e-01],\n",
      "          [ 2.7175e-01,  3.1977e-01,  3.3712e-01]],\n",
      "\n",
      "         [[-2.1678e-02, -1.6564e-02, -1.9633e-02],\n",
      "          [-2.6842e-02, -2.6796e-02, -1.8289e-02],\n",
      "          [-3.1640e-02, -2.6606e-02, -2.1351e-02]],\n",
      "\n",
      "         [[ 9.8869e-02,  6.1214e-02,  4.9423e-02],\n",
      "          [ 1.0447e-01,  9.0694e-02,  5.3494e-02],\n",
      "          [ 6.0943e-02,  7.7955e-02,  6.2396e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3347e-01,  1.3061e-01,  9.6718e-02],\n",
      "          [ 1.0618e-01,  1.3050e-01,  1.2523e-01],\n",
      "          [ 8.1703e-02,  8.8248e-02,  8.9368e-02]],\n",
      "\n",
      "         [[ 1.4484e-02,  8.5306e-03,  5.2609e-03],\n",
      "          [ 1.8192e-02,  1.2974e-02,  8.7990e-03],\n",
      "          [ 1.4381e-02,  8.2296e-03,  8.7859e-03]],\n",
      "\n",
      "         [[ 1.9891e-03,  3.6483e-03,  3.0044e-03],\n",
      "          [ 4.5158e-03,  2.8783e-03,  1.6608e-03],\n",
      "          [ 5.1670e-03,  4.6063e-03,  1.4365e-03]],\n",
      "\n",
      "         [[ 1.0777e-02,  1.0954e-02,  1.5760e-02],\n",
      "          [ 2.0331e-02,  1.9356e-02,  1.6470e-02],\n",
      "          [ 2.0952e-02,  1.8580e-02,  1.3558e-02]],\n",
      "\n",
      "         [[ 5.0361e-03,  3.1652e-03,  1.1828e-03],\n",
      "          [ 7.3658e-03,  5.7190e-03,  1.8905e-03],\n",
      "          [ 6.6480e-03,  6.1843e-03,  1.7227e-03]],\n",
      "\n",
      "         [[ 5.5870e-02,  6.1580e-02,  7.9768e-02],\n",
      "          [ 5.9059e-02,  6.3343e-02,  9.1651e-02],\n",
      "          [ 5.2471e-02,  5.8329e-02,  7.9861e-02]],\n",
      "\n",
      "         [[ 1.6271e-02,  1.3190e-02,  1.4618e-02],\n",
      "          [ 2.0328e-02,  1.3196e-02,  7.7651e-03],\n",
      "          [ 1.1189e-02,  9.2985e-03,  9.1944e-03]],\n",
      "\n",
      "         [[ 6.6541e-03,  6.7370e-03,  8.2035e-03],\n",
      "          [ 4.3636e-03,  7.0579e-03,  9.7437e-03],\n",
      "          [ 3.9674e-03,  8.3003e-03,  1.3528e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7804e-01,  3.4066e-01,  3.1010e-01],\n",
      "          [ 2.8151e-01,  3.7520e-01,  2.7311e-01],\n",
      "          [ 2.6895e-01,  3.2925e-01,  1.8532e-01]],\n",
      "\n",
      "         [[ 4.0547e-02,  3.3016e-02,  2.8065e-02],\n",
      "          [ 4.1348e-02,  1.1973e-02,  1.4213e-02],\n",
      "          [ 3.0400e-02,  2.4052e-02,  1.6162e-02]],\n",
      "\n",
      "         [[ 2.9629e-03,  1.0365e-02,  2.3249e-03],\n",
      "          [ 4.9669e-03,  5.7311e-03, -4.4174e-03],\n",
      "          [ 1.1702e-02,  8.8676e-03, -1.1952e-03]],\n",
      "\n",
      "         [[ 7.4521e-02,  7.0832e-02,  6.6031e-02],\n",
      "          [ 8.3370e-02,  8.3406e-02,  6.7535e-02],\n",
      "          [ 9.9311e-02,  9.9953e-02,  5.8882e-02]],\n",
      "\n",
      "         [[-1.0369e-02, -1.2788e-02, -3.5573e-03],\n",
      "          [-1.0017e-02, -1.3266e-02, -4.3615e-03],\n",
      "          [-8.2894e-03, -1.1520e-02, -3.8726e-03]],\n",
      "\n",
      "         [[ 3.3956e-01,  2.8697e-01,  3.1044e-01],\n",
      "          [ 3.0411e-01,  2.6411e-01,  2.7721e-01],\n",
      "          [ 3.0886e-01,  2.6774e-01,  2.9950e-01]],\n",
      "\n",
      "         [[-6.4443e-02, -6.1512e-02, -7.9516e-02],\n",
      "          [-5.8155e-02, -6.3311e-02, -7.7082e-02],\n",
      "          [-5.6859e-02, -6.0576e-02, -6.9956e-02]],\n",
      "\n",
      "         [[ 7.8428e-02,  9.7788e-02,  1.2960e-01],\n",
      "          [ 9.5404e-02,  1.0057e-01,  7.9579e-02],\n",
      "          [ 8.1995e-02,  9.7000e-02,  5.6768e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2625e-01,  2.0057e-01,  2.4874e-01],\n",
      "          [ 4.2611e-01,  3.9119e-01,  3.4250e-01],\n",
      "          [ 2.2803e-01,  8.8110e-02,  6.3536e-03]],\n",
      "\n",
      "         [[ 4.8644e-02,  3.7643e-02,  3.7249e-02],\n",
      "          [ 5.1050e-02,  2.6109e-02,  1.1362e-02],\n",
      "          [ 2.3018e-02,  1.9021e-02,  4.9762e-03]],\n",
      "\n",
      "         [[ 3.4449e-03,  6.4510e-03,  1.4400e-02],\n",
      "          [-3.2578e-03, -8.4294e-03, -6.3866e-03],\n",
      "          [ 9.7497e-03, -4.2177e-03, -4.4620e-03]],\n",
      "\n",
      "         [[ 8.9896e-02,  9.2880e-02,  1.2181e-01],\n",
      "          [ 9.3543e-02,  1.1103e-01,  1.4400e-01],\n",
      "          [ 5.8145e-02,  4.0206e-02,  4.6897e-02]],\n",
      "\n",
      "         [[-5.9402e-03, -4.9284e-03, -1.3930e-03],\n",
      "          [-2.6309e-03, -6.0076e-04,  8.0209e-04],\n",
      "          [ 6.6776e-04,  1.4777e-03, -1.5775e-03]],\n",
      "\n",
      "         [[ 2.7862e-01,  2.9158e-01,  3.2176e-01],\n",
      "          [ 2.9229e-01,  3.4607e-01,  4.1321e-01],\n",
      "          [ 2.8037e-01,  3.3776e-01,  3.8956e-01]],\n",
      "\n",
      "         [[-2.4129e-02, -1.2970e-02, -4.9139e-03],\n",
      "          [-2.8629e-02, -4.0656e-02, -3.8572e-02],\n",
      "          [-5.3968e-02, -5.7784e-02, -4.3739e-02]],\n",
      "\n",
      "         [[ 6.6441e-02,  6.5164e-02,  4.4061e-02],\n",
      "          [ 7.6738e-02,  1.0585e-01,  6.6969e-02],\n",
      "          [ 7.5866e-02,  1.0473e-01,  8.5972e-02]]]])], 'ds10.conv2.0.bias': [tensor([ 3.0953e-01,  2.2733e-01,  8.6136e-05,  7.6434e-02,  3.9001e-02,\n",
      "         6.9539e-02, -7.2484e-02,  2.5202e-02])], 'ds10.conv3.0.weight': [tensor([[[[ 0.2992,  0.2489,  0.1843],\n",
      "          [ 0.3191,  0.2552,  0.1518],\n",
      "          [ 0.3166,  0.2485,  0.1526]],\n",
      "\n",
      "         [[-0.1421, -0.0372, -0.0695],\n",
      "          [-0.1203, -0.0282, -0.0784],\n",
      "          [-0.1621, -0.1094, -0.1577]],\n",
      "\n",
      "         [[ 0.0061,  0.0055,  0.0047],\n",
      "          [ 0.0067,  0.0058,  0.0055],\n",
      "          [ 0.0057,  0.0059,  0.0052]],\n",
      "\n",
      "         [[-0.4518, -0.5376, -0.4348],\n",
      "          [-0.3332, -0.4500, -0.4178],\n",
      "          [-0.3239, -0.4135, -0.4057]],\n",
      "\n",
      "         [[-0.6067, -0.7687, -0.8767],\n",
      "          [-0.5360, -0.6629, -0.8957],\n",
      "          [-0.6399, -0.5906, -0.7918]],\n",
      "\n",
      "         [[ 0.0255,  0.0276,  0.0349],\n",
      "          [ 0.0431,  0.0386,  0.0435],\n",
      "          [ 0.0430,  0.0423,  0.0428]],\n",
      "\n",
      "         [[-0.5337, -0.6441, -0.5855],\n",
      "          [-0.5229, -0.5643, -0.5324],\n",
      "          [-0.5902, -0.5149, -0.4727]],\n",
      "\n",
      "         [[-0.6504, -0.7355, -0.6172],\n",
      "          [-0.3763, -0.3447, -0.2192],\n",
      "          [-0.3020, -0.2622, -0.2755]]]])], 'ds10.conv3.0.bias': [tensor([0.5098])]}\n",
      "=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
      "abs_grads_dict : \n",
      " {'ds10.layernorm.weight': [tensor(0.2713)], 'ds10.layernorm.bias': [tensor(-0.0015)], 'ds10.conv1.0.weight': [tensor(-0.0003)], 'ds10.conv1.0.bias': [tensor(0.1795)], 'ds10.conv2.0.weight': [tensor(0.0955)], 'ds10.conv2.0.bias': [tensor(0.0843)], 'ds10.conv3.0.weight': [tensor(-0.2391)], 'ds10.conv3.0.bias': [tensor(0.5098)]}\n"
     ]
    }
   ],
   "source": [
    "grads_dict = {}\n",
    "mean_grads_dict = {}\n",
    "\n",
    "for name, params in model_tail.named_parameters():\n",
    "    if (name not in grads_dict) and (\"ds10\" in name):\n",
    "        grads_dict[name] = []\n",
    "        mean_grads_dict[name] = []\n",
    "    if params.grad is not None:\n",
    "        grads_dict[name].append(params.grad)\n",
    "        mean_grads_dict[name].append(params.grad.mean())\n",
    "\n",
    "\n",
    "print(\"grads_dict : \\n\", grads_dict)\n",
    "print(\"=+\" * 15)\n",
    "print(\"abs_grads_dict : \\n\", mean_grads_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_weight_grad = model_tail.ds10.layernorm.weight.grad\n",
    "tail_bias_grad = model_tail.ds10.layernorm.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are around 20 tensors\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n",
      "torch.Size([2, 8, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "model_body_output = []\n",
    "with h5py.File('params_and_grads/h5_body_values.hdf5', 'r') as fbody:\n",
    "    print(f\"there are around {len(fbody.items())} tensors\")\n",
    "    for key, group_val in fbody.items():\n",
    "        blayer_tensor = torch.tensor(group_val['skip9'][:], requires_grad=True).to(device)\n",
    "        print(blayer_tensor.shape)\n",
    "        print(blayer_tensor.unsqueeze)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 2.7019e+00,  2.4791e+00,  8.8414e-01,  ...,  3.9019e+00,\n",
       "             4.7333e+00,  2.0789e+00],\n",
       "           [ 2.0556e+00,  3.9889e+00,  3.6516e+00,  ...,  8.0017e+00,\n",
       "             5.7907e+00,  3.0306e+00],\n",
       "           [ 2.7455e+00,  4.9532e+00,  4.3155e+00,  ...,  5.0719e+00,\n",
       "             4.0301e+00,  4.8240e+00],\n",
       "           ...,\n",
       "           [ 1.4396e+00,  4.3965e+00,  2.3380e+00,  ...,  3.5045e+00,\n",
       "             4.7522e-01,  1.6790e-01],\n",
       "           [ 2.7240e+00,  6.1247e+00,  8.9059e+00,  ...,  3.9794e+00,\n",
       "             5.6375e+00,  5.7376e-02],\n",
       "           [ 1.9277e+00,  1.9695e+00,  1.3725e+00,  ...,  7.2240e-01,\n",
       "             1.9424e+00,  9.7450e-01]],\n",
       "\n",
       "          [[-1.9814e-02,  4.7274e-01, -6.3021e-02,  ..., -1.5852e-01,\n",
       "            -6.9555e-02,  2.8797e-01],\n",
       "           [-3.6659e-01,  6.3267e-02,  1.0207e+00,  ...,  4.4546e+00,\n",
       "             8.6559e-01,  9.5499e-01],\n",
       "           [ 9.6840e-02,  1.9394e+00,  3.6090e+00,  ..., -1.7593e-01,\n",
       "             9.1913e-01,  5.7595e+00],\n",
       "           ...,\n",
       "           [ 1.4916e+00,  1.5340e-01,  4.5763e+00,  ..., -1.5696e-01,\n",
       "             3.6932e+00, -4.8413e-01],\n",
       "           [ 3.3291e+00,  4.2724e+00,  1.1052e+00,  ..., -1.4848e-01,\n",
       "             6.1233e+00,  8.6009e-01],\n",
       "           [-3.0825e-01, -1.6040e-01,  3.9047e+00,  ...,  1.6515e+00,\n",
       "             7.9799e-01,  4.8191e+00]],\n",
       "\n",
       "          [[ 1.6024e+00,  9.4623e-02,  1.1015e-01,  ...,  8.6620e-02,\n",
       "             1.1213e-01,  4.6416e-02],\n",
       "           [ 2.5846e+00,  2.0091e-01,  1.3947e-02,  ...,  1.5292e-01,\n",
       "             1.8908e-01,  1.4785e-01],\n",
       "           [-4.0933e-02,  2.7297e-01,  1.2568e-01,  ...,  1.3802e-01,\n",
       "             9.5634e-02,  1.3709e+00],\n",
       "           ...,\n",
       "           [-2.8792e-02,  1.1353e-01,  2.4006e+00,  ...,  2.1439e-01,\n",
       "             2.5197e-02, -1.7805e-02],\n",
       "           [ 1.3531e-01,  1.7484e-01,  3.5890e-02,  ...,  5.5990e+00,\n",
       "             1.9448e-01,  3.0998e-01],\n",
       "           [ 2.2141e+00, -3.2478e-02, -1.5354e-01,  ...,  8.7159e-02,\n",
       "             6.9872e-01, -7.4975e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 9.1654e-01,  3.0364e-01,  1.6561e+00,  ...,  1.6592e+00,\n",
       "             1.5771e-01,  4.2923e-01],\n",
       "           [ 1.7954e+00,  2.8958e-01, -1.3527e-01,  ...,  1.5812e+00,\n",
       "             1.2191e+00, -2.1479e-01],\n",
       "           [ 2.9183e-01,  2.1580e+00, -2.2137e-01,  ..., -4.6549e-02,\n",
       "             1.6406e+00,  2.3233e-01],\n",
       "           ...,\n",
       "           [ 1.8894e+00,  1.1205e-01,  5.5776e+00,  ...,  6.7216e-01,\n",
       "             2.3561e+00,  1.5737e+00],\n",
       "           [ 1.8565e+00,  1.7623e-01, -1.6486e-01,  ...,  8.5032e-01,\n",
       "            -2.8253e-01,  2.9568e+00],\n",
       "           [ 2.2595e+00, -1.4328e-01,  4.6910e-01,  ...,  5.4269e-01,\n",
       "             7.1000e-02,  9.8840e-02]],\n",
       "\n",
       "          [[-3.4922e-01, -4.9240e-01, -4.2679e-01,  ...,  6.3621e-02,\n",
       "             9.9652e-01,  3.8965e-01],\n",
       "           [-2.8919e-01,  1.0589e-01, -7.1226e-01,  ..., -4.4659e-01,\n",
       "             1.2604e+00,  5.5612e-01],\n",
       "           [-1.9669e-01, -7.3884e-01,  6.4109e-01,  ..., -7.6141e-01,\n",
       "            -6.8705e-01,  1.7000e+00],\n",
       "           ...,\n",
       "           [ 1.9158e+00,  1.3332e+00,  4.6777e+00,  ...,  7.3765e-01,\n",
       "             2.6902e-01,  1.6701e-01],\n",
       "           [ 1.5909e+00,  1.6316e+00,  7.1789e-01,  ...,  4.0766e+00,\n",
       "             2.6511e+00,  1.5001e-01],\n",
       "           [ 8.5433e-01,  9.2875e-01, -3.3396e-01,  ...,  1.4812e+00,\n",
       "             1.0079e+00, -9.9205e-02]],\n",
       "\n",
       "          [[ 1.5411e+00,  5.3699e+00,  1.5678e+00,  ...,  2.8182e+00,\n",
       "             4.2106e+00,  3.0375e+00],\n",
       "           [ 3.6746e+00, -1.3981e-01,  4.5375e+00,  ...,  7.7853e+00,\n",
       "             3.7043e+00,  4.2875e+00],\n",
       "           [ 6.5453e+00,  7.3315e+00,  1.2145e+00,  ...,  1.0501e+01,\n",
       "             5.1399e+00,  3.3373e+00],\n",
       "           ...,\n",
       "           [ 7.8462e+00, -1.3975e-01,  6.5054e+00,  ...,  5.9683e+00,\n",
       "             7.2669e+00,  3.5147e+00],\n",
       "           [ 6.5648e+00,  6.9672e+00,  9.0604e+00,  ...,  8.3384e+00,\n",
       "             1.0298e+01,  4.1254e-01],\n",
       "           [ 2.9761e+00,  4.5352e+00,  6.4592e+00,  ..., -5.5022e-02,\n",
       "             1.1593e-01,  1.2916e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 3.0393e+00,  4.7037e-01,  7.6468e+00,  ...,  4.9632e+00,\n",
       "             7.7710e+00,  1.9100e+00],\n",
       "           [ 4.2089e+00,  5.4480e+00,  6.1009e+00,  ...,  7.2033e+00,\n",
       "             6.8211e+00,  8.0880e-01],\n",
       "           [ 3.4925e+00,  7.4024e+00,  2.5861e+00,  ...,  6.2873e+00,\n",
       "             7.5071e+00,  2.1042e-01],\n",
       "           ...,\n",
       "           [ 1.7260e+00,  5.3989e+00,  5.5153e+00,  ...,  3.6165e+00,\n",
       "             5.8209e+00,  5.9176e-01],\n",
       "           [ 3.6591e+00,  3.8789e+00,  4.5528e+00,  ...,  4.1208e+00,\n",
       "             4.9193e+00,  2.5113e+00],\n",
       "           [ 7.7952e-01,  2.6823e+00,  1.7313e+00,  ...,  1.8108e+00,\n",
       "             1.2390e+00,  1.0254e-01]],\n",
       "\n",
       "          [[-4.3878e-01, -8.8798e-02,  7.7603e-02,  ...,  5.6240e-01,\n",
       "             4.4510e-01,  1.5791e+00],\n",
       "           [-2.9139e-01, -1.1958e-01,  2.5197e+00,  ..., -2.1977e-01,\n",
       "             2.5915e+00,  7.3488e-02],\n",
       "           [-3.8791e-01, -2.1390e-01,  2.9834e+00,  ..., -1.7883e-01,\n",
       "             4.5792e+00,  3.5988e+00],\n",
       "           ...,\n",
       "           [ 2.4552e-02,  4.8020e+00,  6.7155e+00,  ...,  8.3028e-01,\n",
       "             1.1311e+00,  2.0531e+00],\n",
       "           [-2.5553e-01,  1.1430e-02,  5.6149e+00,  ..., -3.8334e-01,\n",
       "            -3.7854e-01,  1.4752e+00],\n",
       "           [ 5.8767e-01,  9.7855e-01,  3.6503e+00,  ...,  2.0457e+00,\n",
       "             1.0854e+00,  1.7717e+00]],\n",
       "\n",
       "          [[-6.1647e-02, -4.0300e-02,  1.4881e-01,  ...,  1.2534e-01,\n",
       "            -3.2814e-02,  8.3390e-02],\n",
       "           [ 1.3879e-01,  8.1311e-02,  6.4996e-01,  ..., -1.6698e-02,\n",
       "             1.7540e-02,  1.0614e-01],\n",
       "           [ 6.8624e-01,  1.0111e+00,  7.5559e-01,  ...,  1.7743e-01,\n",
       "             9.5566e-03,  1.6461e-01],\n",
       "           ...,\n",
       "           [ 5.2140e-01,  4.5892e-02,  1.7335e-01,  ...,  1.2421e+00,\n",
       "             1.1445e+00,  4.1462e-02],\n",
       "           [ 9.7988e-02,  1.9042e+00,  1.0399e+00,  ...,  5.8679e-01,\n",
       "             4.5879e-01,  1.2660e+00],\n",
       "           [-2.6848e-01,  1.3908e-01, -2.8077e-02,  ..., -1.4164e-01,\n",
       "            -1.7733e-01,  7.3502e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 6.0760e-01,  1.3703e+00,  4.4031e-01,  ..., -4.2165e-01,\n",
       "             2.2920e+00,  1.1429e-01],\n",
       "           [ 1.6807e+00,  3.9802e+00,  1.4880e+00,  ...,  4.4907e+00,\n",
       "             2.1136e+00,  5.5733e-01],\n",
       "           [ 3.3540e-01,  3.7194e-01,  6.5472e-01,  ...,  2.3160e+00,\n",
       "             6.4056e-01,  1.3526e+00],\n",
       "           ...,\n",
       "           [ 2.9873e+00,  1.3177e+00, -2.3748e-01,  ...,  1.2231e+00,\n",
       "             8.0568e-01,  5.2564e-02],\n",
       "           [-3.5259e-02,  2.6969e-01,  3.5793e+00,  ...,  8.1611e-01,\n",
       "            -3.2841e-01,  1.6009e+00],\n",
       "           [-1.3515e-01, -2.9335e-01,  6.1708e-01,  ..., -2.5468e-01,\n",
       "            -2.2342e-01,  4.2451e-01]],\n",
       "\n",
       "          [[-1.3640e-01, -5.1353e-01, -6.7931e-01,  ..., -5.4940e-01,\n",
       "            -7.2404e-01,  2.5345e+00],\n",
       "           [-1.2308e-01, -8.0100e-01, -7.7184e-01,  ..., -6.2127e-01,\n",
       "             1.1997e+00,  2.7528e+00],\n",
       "           [-1.7592e-01, -7.9541e-01, -7.9039e-01,  ...,  3.2834e-02,\n",
       "             2.9778e+00,  9.1063e-01],\n",
       "           ...,\n",
       "           [ 1.3283e+00,  1.0376e-01,  3.0282e-01,  ..., -7.5052e-01,\n",
       "            -7.7909e-01,  1.4063e+00],\n",
       "           [ 8.0147e-01,  8.4890e-01, -7.6986e-01,  ..., -7.3230e-01,\n",
       "             4.6001e-02, -4.4644e-01],\n",
       "           [ 1.5275e+00,  7.1970e-01, -3.3770e-01,  ..., -4.7318e-01,\n",
       "            -4.5862e-01, -5.0171e-01]],\n",
       "\n",
       "          [[ 7.5298e-01,  2.5778e-01,  2.9239e+00,  ..., -2.4928e-01,\n",
       "             4.0431e+00,  3.7624e+00],\n",
       "           [ 4.0432e+00, -1.1252e-01,  6.2689e+00,  ...,  5.7560e+00,\n",
       "             6.9580e+00,  3.9510e+00],\n",
       "           [ 2.5848e+00,  8.3513e+00, -1.2746e-01,  ...,  9.7049e+00,\n",
       "             7.5631e+00,  2.1229e+00],\n",
       "           ...,\n",
       "           [ 3.6948e+00,  8.3830e+00,  5.6537e+00,  ...,  4.5965e+00,\n",
       "             5.0082e+00,  2.0666e+00],\n",
       "           [ 5.6968e+00,  3.2627e+00,  6.3997e+00,  ...,  3.1536e+00,\n",
       "             1.6104e+00,  9.6064e-01],\n",
       "           [ 2.5749e+00,  2.1849e+00,  3.8733e+00,  ...,  1.4316e-01,\n",
       "            -1.3965e-01, -2.6839e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.8151e+00,  5.5297e+00,  5.9492e+00,  ...,  9.9592e-01,\n",
       "             1.7091e-01,  1.8935e+00],\n",
       "           [ 2.6067e+00,  7.1662e+00,  3.9153e+00,  ...,  4.3761e+00,\n",
       "             6.0730e+00,  2.0106e+00],\n",
       "           [ 4.4862e+00,  3.4625e+00,  5.6404e+00,  ...,  5.0567e+00,\n",
       "             5.9484e+00,  2.8162e+00],\n",
       "           ...,\n",
       "           [ 2.5206e+00,  5.5530e+00,  5.3781e+00,  ...,  5.2384e+00,\n",
       "             1.4006e+00,  4.4060e+00],\n",
       "           [ 5.5689e+00,  6.8676e+00,  5.3611e+00,  ...,  1.5652e+00,\n",
       "             3.9252e+00,  2.6294e+00],\n",
       "           [ 2.3599e+00,  4.7874e+00,  1.5315e+00,  ...,  6.0348e-01,\n",
       "             7.9402e-01,  1.4820e+00]],\n",
       "\n",
       "          [[-4.2556e-01, -1.9900e-01, -3.2495e-01,  ...,  5.2572e-01,\n",
       "             5.9069e-01, -3.9718e-01],\n",
       "           [-3.7437e-01,  2.5096e+00,  1.2601e+00,  ...,  2.7492e+00,\n",
       "             1.3280e-01,  1.9419e+00],\n",
       "           [-4.2690e-01, -2.1157e-01, -3.4269e-01,  ..., -2.3560e-01,\n",
       "            -3.5609e-01,  1.1046e+00],\n",
       "           ...,\n",
       "           [-4.2695e-01,  2.3178e+00,  6.1045e-01,  ...,  2.3713e+00,\n",
       "            -2.0561e-01,  2.7152e+00],\n",
       "           [ 1.1810e+00, -2.9417e-02,  3.4543e+00,  ..., -1.8063e-01,\n",
       "             3.6092e+00, -3.4946e-01],\n",
       "           [ 1.0370e+00,  3.5248e+00,  1.6642e+00,  ...,  1.8308e+00,\n",
       "             2.1220e+00,  9.7614e-01]],\n",
       "\n",
       "          [[ 2.3372e-01,  1.4536e-01,  9.8700e-01,  ...,  1.0447e-01,\n",
       "             7.0816e-01,  5.6159e-01],\n",
       "           [ 1.2389e-01,  5.7520e-02,  2.0982e-02,  ...,  5.4832e-01,\n",
       "             1.5921e+00,  1.8657e-01],\n",
       "           [ 2.8698e+00,  9.7534e-02,  6.1215e-01,  ...,  1.3664e-02,\n",
       "             1.8505e-01,  2.7563e-01],\n",
       "           ...,\n",
       "           [-2.1909e-02,  4.7135e-01,  4.3908e-01,  ...,  2.1836e+00,\n",
       "             1.9002e-01, -2.8846e-02],\n",
       "           [ 1.1784e-01,  2.6240e-01,  3.0128e-02,  ...,  1.2539e-01,\n",
       "             9.5286e-02,  2.5435e-01],\n",
       "           [-1.6767e-01, -1.5820e-01, -1.0980e-01,  ..., -1.8636e-01,\n",
       "            -3.1285e-02,  8.5810e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 1.0286e-01,  1.9316e+00,  1.9680e+00,  ...,  1.3374e+00,\n",
       "             6.9761e-01,  1.5245e+00],\n",
       "           [ 7.3377e-01,  6.2054e-02,  3.6511e-02,  ...,  1.1690e+00,\n",
       "            -1.5054e-01,  2.6942e-01],\n",
       "           [ 1.6484e+00, -2.5482e-01,  8.5361e-01,  ...,  9.8446e-01,\n",
       "             9.3097e-01,  2.5437e+00],\n",
       "           ...,\n",
       "           [-2.4382e-03,  7.6640e-01,  4.6748e+00,  ..., -6.7634e-02,\n",
       "            -1.8304e-01,  2.5165e-01],\n",
       "           [ 5.1818e-01, -3.9561e-01,  1.0247e+00,  ..., -4.0099e-01,\n",
       "            -2.8988e-01,  4.4215e-01],\n",
       "           [ 4.9094e-01,  2.7407e+00,  5.5349e-01,  ...,  2.3090e-01,\n",
       "            -2.6774e-01,  8.9559e-02]],\n",
       "\n",
       "          [[-4.2601e-01, -1.3536e-01, -6.7617e-01,  ..., -5.7807e-01,\n",
       "             1.3202e+00, -1.8417e-01],\n",
       "           [-2.4208e-01, -7.9992e-01, -7.8978e-01,  ..., -7.9439e-01,\n",
       "            -6.0654e-01,  2.4221e+00],\n",
       "           [ 1.1060e+00,  6.0130e-01, -8.1278e-01,  ..., -6.7324e-01,\n",
       "             6.5760e-01,  1.3384e+00],\n",
       "           ...,\n",
       "           [ 4.0749e+00,  8.2896e-01,  8.2573e-01,  ..., -7.0837e-01,\n",
       "            -7.0237e-01, -6.0054e-01],\n",
       "           [ 3.6074e+00,  1.1218e-01,  1.8680e+00,  ..., -7.8943e-02,\n",
       "            -6.9482e-01,  3.6469e-01],\n",
       "           [ 2.2281e+00, -3.9818e-01,  2.7012e+00,  ..., -3.8249e-01,\n",
       "            -5.1227e-01, -3.6029e-01]],\n",
       "\n",
       "          [[ 2.4206e+00,  3.0104e+00,  3.0008e+00,  ...,  3.7331e+00,\n",
       "             1.1165e+00,  1.4400e+00],\n",
       "           [ 3.6913e+00,  8.7564e+00,  6.8555e+00,  ...,  5.9000e+00,\n",
       "             9.1127e+00,  1.9890e+00],\n",
       "           [ 5.6943e+00,  5.6949e+00,  5.2574e+00,  ...,  6.2274e+00,\n",
       "             4.0272e+00,  3.8945e+00],\n",
       "           ...,\n",
       "           [ 5.2471e+00,  7.5147e+00,  3.9716e+00,  ...,  5.4981e+00,\n",
       "             2.5621e+00,  1.7240e+00],\n",
       "           [ 4.1142e+00,  7.4528e+00,  4.5772e+00,  ...,  3.4864e+00,\n",
       "             2.9380e+00,  7.9901e-01],\n",
       "           [ 3.0245e+00,  2.6082e+00,  3.0484e+00,  ...,  7.7454e-01,\n",
       "             1.2018e+00, -2.8326e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 1.6735e+00,  3.8294e+00,  1.8857e+00,  ...,  3.6812e+00,\n",
       "             5.3681e+00,  1.7002e+00],\n",
       "           [ 1.8814e+00,  4.8775e+00,  2.3839e+00,  ...,  5.4532e+00,\n",
       "             5.3314e+00,  4.0417e+00],\n",
       "           [ 6.0796e+00,  3.7512e+00,  2.0436e+00,  ...,  4.6764e+00,\n",
       "             3.3870e+00,  3.0130e+00],\n",
       "           ...,\n",
       "           [ 4.7889e+00,  5.9661e+00,  7.6774e+00,  ...,  2.7749e+00,\n",
       "             4.0787e+00,  3.0704e+00],\n",
       "           [ 2.5288e-01,  5.1166e+00,  6.1208e+00,  ...,  1.6799e+00,\n",
       "             5.1126e+00,  1.2680e+00],\n",
       "           [ 1.2418e+00,  2.8463e+00,  5.6512e-01,  ...,  1.8398e+00,\n",
       "             3.8873e-01,  1.5866e+00]],\n",
       "\n",
       "          [[-3.5788e-01, -3.0676e-01,  2.6663e-01,  ...,  7.3644e-01,\n",
       "             2.9794e-01, -3.0539e-01],\n",
       "           [-3.4423e-01,  5.4155e-01, -8.0123e-02,  ...,  8.4812e-01,\n",
       "             2.5593e+00, -2.5894e-01],\n",
       "           [-4.3614e-01,  1.6834e+00,  1.6594e+00,  ...,  3.4567e+00,\n",
       "             4.8887e+00,  3.5413e+00],\n",
       "           ...,\n",
       "           [-4.5864e-01,  1.1329e+00,  3.6858e+00,  ...,  2.2659e+00,\n",
       "             7.4997e-03,  1.8813e+00],\n",
       "           [-4.2394e-01,  3.4810e+00,  2.9686e+00,  ...,  3.4551e-01,\n",
       "            -2.1203e-01,  1.2380e+00],\n",
       "           [ 1.4029e+00,  1.4513e+00,  4.6256e+00,  ...,  8.8034e-01,\n",
       "             8.5659e-01,  1.5566e+00]],\n",
       "\n",
       "          [[ 1.5123e+00,  7.1269e-01, -3.1596e-02,  ..., -2.9687e-02,\n",
       "             3.8520e-01, -8.2944e-02],\n",
       "           [ 4.9912e-01,  6.6972e-01,  1.1238e+00,  ...,  2.8954e-01,\n",
       "             1.3923e-01,  1.2197e-01],\n",
       "           [-7.1127e-02,  1.9344e-01,  1.7784e-01,  ...,  3.7304e-02,\n",
       "             1.0731e-01,  1.0211e-02],\n",
       "           ...,\n",
       "           [ 1.1541e-01,  1.1026e-01,  1.8687e-01,  ...,  5.3324e-01,\n",
       "             3.2969e-02, -4.1239e-04],\n",
       "           [-1.3138e-02,  1.9272e-01,  1.7513e-01,  ...,  1.6685e-01,\n",
       "             1.2290e+00, -3.4881e-02],\n",
       "           [-6.0080e-02, -1.8937e-01,  1.1516e+00,  ..., -1.3861e-01,\n",
       "            -1.3863e-01, -9.5302e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 1.5501e+00,  1.5155e+00,  1.6587e+00,  ...,  8.6501e-01,\n",
       "             6.7495e-01,  4.6660e-01],\n",
       "           [ 1.4548e+00,  7.4643e-01,  2.2756e-01,  ...,  1.7307e+00,\n",
       "             1.9086e+00,  2.3386e+00],\n",
       "           [ 1.2346e+00,  1.7829e+00,  4.3349e-01,  ...,  1.3556e+00,\n",
       "            -3.6194e-01, -2.0110e-01],\n",
       "           ...,\n",
       "           [ 1.5173e+00,  3.5384e+00, -3.8452e-01,  ...,  5.9512e-01,\n",
       "             2.0566e-01,  2.3969e-01],\n",
       "           [ 7.5797e-01,  4.5428e-01,  1.7409e+00,  ...,  8.1221e-02,\n",
       "             2.5345e-01,  7.8171e-02],\n",
       "           [ 4.2597e-01, -1.7485e-01,  1.4600e+00,  ..., -3.1704e-01,\n",
       "            -2.5954e-01, -2.4897e-01]],\n",
       "\n",
       "          [[-4.7571e-01,  4.4082e-01, -5.3556e-01,  ..., -4.4832e-01,\n",
       "            -6.4508e-01,  1.6938e+00],\n",
       "           [-4.1798e-01,  1.3899e+00, -7.0305e-01,  ..., -6.5829e-01,\n",
       "             7.4532e-01,  5.4459e-01],\n",
       "           [-3.6111e-01, -8.1480e-01, -7.9673e-01,  ..., -8.0759e-01,\n",
       "            -6.3827e-01, -4.3785e-01],\n",
       "           ...,\n",
       "           [-4.7011e-01, -3.2330e-01,  2.0323e+00,  ..., -6.9636e-01,\n",
       "            -7.6590e-01, -4.8718e-01],\n",
       "           [ 2.8574e-02,  3.0662e-01,  1.0094e+00,  ..., -7.2997e-01,\n",
       "            -8.5289e-01, -1.2389e-01],\n",
       "           [ 9.5105e-01,  3.1285e+00,  6.5684e-01,  ..., -2.7473e-01,\n",
       "            -4.2282e-01, -4.3211e-01]],\n",
       "\n",
       "          [[ 2.7601e+00,  4.5984e+00,  4.8908e+00,  ...,  3.2411e+00,\n",
       "             4.4881e+00,  3.6303e+00],\n",
       "           [ 2.6394e+00,  6.2871e+00,  3.5135e+00,  ...,  8.1197e+00,\n",
       "             5.4095e+00,  3.7844e+00],\n",
       "           [ 6.4921e+00,  4.3732e+00,  5.9322e+00,  ...,  6.0641e+00,\n",
       "             7.3301e+00,  1.4526e+00],\n",
       "           ...,\n",
       "           [ 6.0442e+00,  1.9703e+00,  1.1606e+01,  ...,  6.8316e+00,\n",
       "             4.5460e+00,  1.4420e+00],\n",
       "           [ 7.6542e+00,  7.5505e+00,  7.2226e+00,  ...,  4.1917e+00,\n",
       "             3.3846e+00,  1.8509e-01],\n",
       "           [ 4.8774e+00,  3.0897e+00,  3.2389e+00,  ...,  3.3162e-01,\n",
       "            -2.7105e-01, -2.5631e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 4.0850e+00,  2.2286e-01,  5.2587e+00,  ...,  6.9359e+00,\n",
       "             6.7540e+00,  3.6886e+00],\n",
       "           [ 3.8750e+00,  1.2351e+00,  5.3955e+00,  ...,  4.1403e+00,\n",
       "             7.7754e+00,  1.3192e+00],\n",
       "           [ 4.1905e+00,  7.4750e+00,  8.8971e-01,  ...,  3.9068e+00,\n",
       "             6.4579e+00,  1.9420e+00],\n",
       "           ...,\n",
       "           [ 2.0877e+00,  4.5306e-01,  5.7872e+00,  ...,  3.0065e+00,\n",
       "             4.2817e-01,  3.9090e-01],\n",
       "           [ 4.8768e+00,  6.3026e+00,  4.2023e-01,  ...,  7.7031e-01,\n",
       "             2.8856e+00,  2.6300e+00],\n",
       "           [ 6.5216e-01,  2.8355e+00,  1.4184e+00,  ...,  3.2486e-01,\n",
       "             1.5783e+00,  7.6026e-01]],\n",
       "\n",
       "          [[-4.3552e-01, -2.1424e-01,  6.4283e-01,  ..., -2.6633e-01,\n",
       "            -1.7926e-01, -2.8619e-01],\n",
       "           [-4.3899e-01,  5.2710e-01,  8.1694e-01,  ...,  3.7516e+00,\n",
       "             5.2767e+00, -3.5536e-01],\n",
       "           [-2.4862e-01,  2.0484e+00, -3.8082e-01,  ...,  4.5853e+00,\n",
       "             2.3320e+00,  1.1152e-01],\n",
       "           ...,\n",
       "           [ 9.6747e-01,  4.3743e+00, -1.9541e-01,  ..., -4.2062e-01,\n",
       "             6.0739e+00,  3.0633e+00],\n",
       "           [-1.6760e-01,  3.4816e+00, -1.6428e-01,  ...,  2.0199e+00,\n",
       "             1.3209e+00,  2.7769e+00],\n",
       "           [ 8.4143e-01,  4.5608e+00,  4.9982e+00,  ...,  2.3833e+00,\n",
       "             6.2182e-01,  1.4096e+00]],\n",
       "\n",
       "          [[-3.6321e-02, -5.5701e-02,  2.1729e+00,  ...,  9.9170e-02,\n",
       "            -3.3037e-02,  9.9166e-02],\n",
       "           [ 1.9785e-02,  6.5810e-02,  2.4077e+00,  ...,  1.2772e-01,\n",
       "            -3.8416e-02,  1.1559e+00],\n",
       "           [ 2.6086e+00,  1.5900e-01,  6.4854e-02,  ...,  1.3522e+00,\n",
       "             1.8099e-01,  3.3038e-01],\n",
       "           ...,\n",
       "           [ 3.4835e-02,  1.1975e+00,  5.3926e-01,  ..., -3.9197e-03,\n",
       "             1.7609e-01,  1.6858e-01],\n",
       "           [ 9.5054e-02, -1.2727e-03,  9.2095e-02,  ...,  3.1203e+00,\n",
       "             2.3940e-01,  1.2702e-01],\n",
       "           [-2.3217e-01, -1.2802e-01,  1.8404e+00,  ..., -2.1549e-01,\n",
       "            -2.5683e-02, -7.5243e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 8.7727e-01,  1.4135e+00,  1.8687e+00,  ...,  2.7481e+00,\n",
       "             2.3212e+00,  1.7903e-01],\n",
       "           [-8.5236e-03,  3.5131e+00, -4.0797e-01,  ...,  5.7770e-01,\n",
       "             3.2168e+00,  1.6539e+00],\n",
       "           [ 6.0651e-02, -3.9717e-01,  4.8873e+00,  ..., -2.1936e-02,\n",
       "             1.2146e-01,  6.0904e-01],\n",
       "           ...,\n",
       "           [ 2.2187e+00,  2.1845e+00, -3.7470e-01,  ...,  1.1985e+00,\n",
       "            -3.8889e-02,  4.9569e-01],\n",
       "           [-1.5495e-01, -3.4886e-01,  4.1413e+00,  ..., -8.5493e-02,\n",
       "            -1.2882e-03, -4.4998e-02],\n",
       "           [ 4.3630e-01, -1.2748e-01,  8.2783e-01,  ...,  3.6383e-01,\n",
       "            -2.0795e-01, -1.2851e-01]],\n",
       "\n",
       "          [[-3.9036e-01, -5.8596e-01, -5.7810e-01,  ..., -3.8580e-01,\n",
       "             1.4068e+00,  1.5090e+00],\n",
       "           [-4.6328e-01, -7.4607e-01, -7.5887e-01,  ..., -6.5058e-01,\n",
       "            -4.8095e-01, -5.3818e-01],\n",
       "           [-3.4983e-01,  1.2791e+00, -1.5817e-01,  ..., -6.4226e-01,\n",
       "             8.1531e-02, -1.0527e-01],\n",
       "           ...,\n",
       "           [-1.8998e-01,  2.5667e+00,  6.6212e-01,  ..., -7.6536e-01,\n",
       "            -4.4186e-01,  1.6025e+00],\n",
       "           [ 1.4644e-01,  3.0177e+00,  4.1025e-01,  ..., -3.7580e-01,\n",
       "            -6.3702e-01,  9.7233e-01],\n",
       "           [ 2.4890e+00,  6.7080e-01, -3.3134e-01,  ..., -2.0861e-01,\n",
       "            -4.2857e-01, -4.5028e-01]],\n",
       "\n",
       "          [[ 2.7694e+00,  3.4585e+00,  3.3767e+00,  ...,  5.6521e+00,\n",
       "             3.8360e+00,  3.2269e+00],\n",
       "           [ 4.6107e+00,  3.3123e+00, -9.1942e-02,  ...,  4.4379e+00,\n",
       "             8.2893e+00,  4.7861e+00],\n",
       "           [ 1.0188e+00,  7.5154e+00, -1.4533e-01,  ...,  6.5363e+00,\n",
       "             2.5964e+00, -3.3319e-02],\n",
       "           ...,\n",
       "           [ 3.3856e+00,  9.0767e+00,  9.4115e+00,  ...,  1.7763e+00,\n",
       "             5.2346e+00,  7.6396e-01],\n",
       "           [ 7.1761e+00,  5.3460e+00,  6.5858e+00,  ...,  7.7286e+00,\n",
       "             4.0678e+00, -1.8403e-01],\n",
       "           [ 3.9415e+00,  4.3015e+00,  4.2832e+00,  ...,  1.4953e+00,\n",
       "             2.2341e-01, -1.4252e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 2.1390e+00,  5.4137e+00,  3.4856e+00,  ...,  3.3192e+00,\n",
       "             3.3041e+00,  2.1409e+00],\n",
       "           [ 4.0920e+00,  3.2158e+00,  3.0807e+00,  ...,  6.5355e-01,\n",
       "             4.4311e+00,  3.6891e+00],\n",
       "           [ 6.3241e+00,  3.3905e+00,  3.6516e+00,  ...,  4.7222e+00,\n",
       "             2.9720e+00,  2.9671e+00],\n",
       "           ...,\n",
       "           [ 2.5676e+00,  4.6192e+00,  4.3488e+00,  ...,  2.7307e+00,\n",
       "             2.9248e+00,  2.1933e+00],\n",
       "           [ 2.8462e-01,  5.1998e-01,  7.4085e+00,  ...,  4.6967e+00,\n",
       "             4.9974e+00,  4.8755e-01],\n",
       "           [ 2.5947e+00,  1.7862e+00,  2.2237e+00,  ...,  1.3348e+00,\n",
       "             1.7132e+00,  6.6579e-01]],\n",
       "\n",
       "          [[-3.7539e-01, -9.2677e-02, -1.1240e-01,  ...,  1.7798e+00,\n",
       "            -3.0524e-01,  8.1554e-01],\n",
       "           [ 1.9176e-01,  2.4694e+00, -2.1448e-01,  ...,  2.8572e+00,\n",
       "             6.6986e-02,  1.1634e+00],\n",
       "           [-3.4014e-01, -2.3735e-01, -1.4262e-01,  ...,  3.8891e+00,\n",
       "             1.9492e+00,  2.3689e+00],\n",
       "           ...,\n",
       "           [-3.9880e-01,  4.7782e+00, -3.9410e-01,  ...,  1.3405e+00,\n",
       "             3.8028e+00,  2.4880e+00],\n",
       "           [-2.8817e-01,  5.6458e-01,  5.9089e+00,  ...,  2.4793e-01,\n",
       "             8.9994e-01,  2.4649e-01],\n",
       "           [ 5.7171e-03,  3.1114e+00,  2.3596e+00,  ...,  1.4049e+00,\n",
       "             2.3113e+00,  1.1585e+00]],\n",
       "\n",
       "          [[-5.2566e-02,  1.4221e-01,  6.5159e-01,  ...,  5.9753e-01,\n",
       "             1.4834e-01, -8.5929e-02],\n",
       "           [ 1.3373e-01,  1.9625e-02,  1.7041e-01,  ...,  1.6429e-01,\n",
       "             1.8079e-01,  1.3031e-01],\n",
       "           [ 2.0580e+00,  4.4865e-02,  1.9530e-01,  ...,  4.5284e-01,\n",
       "             1.3091e-01,  1.0617e-01],\n",
       "           ...,\n",
       "           [-4.6191e-04,  1.7135e-01,  2.3637e-02,  ...,  1.4544e+00,\n",
       "             8.3269e-02,  1.7926e-01],\n",
       "           [ 1.3052e-01,  2.5127e-02,  1.1182e-01,  ...,  4.6139e-01,\n",
       "            -1.0337e-02,  5.5763e-02],\n",
       "           [-2.5886e-01, -9.5752e-02,  3.2785e-01,  ..., -1.3968e-01,\n",
       "            -2.4155e-01,  8.2592e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-2.4722e-01,  9.4161e-01,  2.4347e+00,  ..., -2.6669e-01,\n",
       "            -2.0088e-01,  3.0580e-01],\n",
       "           [ 6.6588e-01,  1.0118e-01,  9.6823e-01,  ..., -4.3169e-01,\n",
       "            -2.2427e-01,  2.2415e-01],\n",
       "           [ 1.6472e-01,  5.3215e-01,  6.6715e-01,  ...,  1.6981e+00,\n",
       "             3.5904e-01,  3.9638e-01],\n",
       "           ...,\n",
       "           [-2.3487e-02, -1.5799e-01,  2.7409e+00,  ...,  5.9899e-01,\n",
       "            -4.7458e-02, -1.4948e-01],\n",
       "           [ 6.4893e-01, -3.9905e-01, -2.0027e-01,  ...,  8.4461e-02,\n",
       "            -3.9694e-02,  4.4743e-01],\n",
       "           [ 3.5825e-01,  1.0612e+00, -2.7075e-01,  ..., -2.6319e-01,\n",
       "            -2.7605e-01,  9.9365e-02]],\n",
       "\n",
       "          [[-4.9206e-01,  2.6622e-01, -1.6979e-02,  ..., -7.2886e-01,\n",
       "            -7.7580e-01, -2.4968e-01],\n",
       "           [-3.4259e-01,  9.8106e-01, -6.5208e-01,  ..., -7.6899e-01,\n",
       "            -7.6694e-01, -3.9301e-01],\n",
       "           [-3.4468e-01,  4.2242e-01, -6.5376e-01,  ..., -3.6199e-01,\n",
       "            -2.9902e-01,  4.4966e-01],\n",
       "           ...,\n",
       "           [-3.9893e-01,  3.9048e+00, -2.3796e-02,  ..., -8.5580e-01,\n",
       "            -8.1046e-01, -7.6619e-01],\n",
       "           [ 1.5548e-02,  3.7853e+00, -7.4249e-01,  ..., -7.3116e-01,\n",
       "            -8.4320e-01, -4.1824e-01],\n",
       "           [ 1.4167e+00, -3.4844e-01,  3.1576e-01,  ..., -3.9175e-01,\n",
       "            -5.4550e-01, -4.2415e-01]],\n",
       "\n",
       "          [[ 1.7097e+00,  1.5204e+00,  3.8103e-01,  ...,  1.8725e+00,\n",
       "             1.9911e+00,  1.1567e+00],\n",
       "           [ 4.2677e+00,  7.0064e+00,  3.7249e+00,  ...,  3.2622e+00,\n",
       "             4.9025e+00,  1.3493e+00],\n",
       "           [ 5.8961e+00,  5.3640e+00,  5.0701e+00,  ...,  8.6190e+00,\n",
       "             4.9125e+00,  3.4457e+00],\n",
       "           ...,\n",
       "           [ 5.3180e+00,  7.5257e+00,  2.2188e+00,  ...,  4.0323e+00,\n",
       "             4.4000e+00,  1.0452e+00],\n",
       "           [ 6.8645e+00,  8.3525e+00,  6.9823e+00,  ...,  2.9436e+00,\n",
       "             2.5634e+00,  1.1892e+00],\n",
       "           [ 4.7540e+00,  1.9005e+00,  5.6853e+00,  ...,  2.8513e-01,\n",
       "            -7.1222e-02, -1.1936e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 2.5544e+00,  3.6247e+00,  3.4967e+00,  ...,  6.6000e+00,\n",
       "             3.8954e+00,  2.1672e+00],\n",
       "           [ 8.3812e+00,  3.7094e+00,  3.2291e+00,  ...,  3.1851e-01,\n",
       "             7.0930e+00,  1.5537e+00],\n",
       "           [ 3.7580e+00,  4.6089e+00,  2.9977e+00,  ...,  1.2929e+00,\n",
       "             4.3384e+00,  7.7281e-01],\n",
       "           ...,\n",
       "           [ 4.2343e+00,  8.8087e+00,  7.9930e+00,  ...,  5.2866e+00,\n",
       "             3.4993e+00,  2.1700e+00],\n",
       "           [ 4.6701e+00,  8.4982e+00,  5.7726e+00,  ...,  5.6105e+00,\n",
       "             6.6983e+00,  2.6835e+00],\n",
       "           [ 2.5654e+00,  2.9972e+00,  1.9513e+00,  ...,  7.5420e-01,\n",
       "             1.0658e+00,  1.1765e+00]],\n",
       "\n",
       "          [[-3.3691e-01, -9.4739e-02, -2.3806e-01,  ...,  4.4862e-01,\n",
       "            -3.3946e-01, -1.4979e-01],\n",
       "           [-3.9495e-01,  3.2491e+00, -1.7115e-01,  ...,  5.0088e-01,\n",
       "             2.0057e+00,  3.7354e+00],\n",
       "           [-4.4126e-01,  2.8299e+00, -1.7711e-01,  ...,  3.8224e+00,\n",
       "             4.3572e+00,  3.7403e+00],\n",
       "           ...,\n",
       "           [-4.3092e-01,  1.1349e+00,  6.7341e+00,  ..., -1.7010e-01,\n",
       "             3.5059e+00,  4.3160e-01],\n",
       "           [-2.1093e-01,  1.2484e+00,  2.2823e+00,  ..., -3.4262e-01,\n",
       "             2.0612e+00,  2.0780e+00],\n",
       "           [ 4.3074e+00,  6.4033e+00,  4.9689e+00,  ..., -1.8527e-01,\n",
       "            -1.4975e-01,  2.1980e+00]],\n",
       "\n",
       "          [[ 1.0204e+00, -4.4208e-02, -3.5922e-02,  ...,  5.8067e-01,\n",
       "             9.7945e-03, -4.1597e-03],\n",
       "           [-5.0574e-02, -2.2127e-02,  8.8084e-01,  ...,  1.6603e-01,\n",
       "             2.0247e-01,  1.6776e-01],\n",
       "           [ 2.5994e+00,  1.1092e+00,  2.3869e-01,  ...,  8.9471e-01,\n",
       "             3.0849e-01,  1.7543e-01],\n",
       "           ...,\n",
       "           [ 8.1106e-03,  1.5774e-02,  1.7163e-01,  ...,  2.0359e-01,\n",
       "             1.6237e-01, -8.7101e-03],\n",
       "           [-8.3076e-03,  1.8564e-01,  4.4597e-02,  ...,  1.4435e+00,\n",
       "            -1.1252e-02,  2.1238e+00],\n",
       "           [-2.1952e-01, -1.2546e-02,  2.5678e+00,  ..., -5.2611e-02,\n",
       "            -1.0614e-02, -1.0937e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 8.0083e-01,  1.3413e+00, -2.2789e-01,  ...,  1.8014e+00,\n",
       "             1.3360e+00,  3.3943e-01],\n",
       "           [ 1.7012e+00,  3.3502e+00,  1.7166e+00,  ...,  1.1569e+00,\n",
       "             2.5988e+00,  1.9087e+00],\n",
       "           [ 2.6706e+00,  5.0913e-01, -1.5068e-01,  ...,  3.9209e+00,\n",
       "            -1.7259e-01,  6.2964e-01],\n",
       "           ...,\n",
       "           [ 1.0417e+00,  2.0098e+00, -3.6214e-01,  ..., -1.4963e-01,\n",
       "             7.0913e-01, -7.8241e-02],\n",
       "           [ 1.5130e+00,  2.7393e-01,  2.6412e+00,  ...,  3.2876e-01,\n",
       "             4.7454e-02,  3.9952e-01],\n",
       "           [ 3.3066e+00,  1.0202e+00,  8.4348e-01,  ..., -1.9611e-01,\n",
       "            -2.2947e-01, -9.5805e-02]],\n",
       "\n",
       "          [[ 5.7439e-01,  4.9616e-01, -5.7783e-01,  ...,  1.0151e+00,\n",
       "            -6.7395e-01,  2.6520e+00],\n",
       "           [-5.2368e-01, -2.5242e-01, -5.6215e-01,  ...,  1.6038e+00,\n",
       "             9.5981e-02,  3.3520e+00],\n",
       "           [-3.6031e-01, -6.1983e-01, -6.6786e-01,  ...,  1.4442e+00,\n",
       "            -6.0413e-01,  3.0507e+00],\n",
       "           ...,\n",
       "           [ 6.5679e-01,  4.6761e+00, -5.0527e-01,  ..., -7.6679e-01,\n",
       "            -6.6869e-01, -2.5917e-01],\n",
       "           [ 2.8712e+00,  3.0580e+00,  1.8174e+00,  ..., -4.5009e-01,\n",
       "            -8.0133e-01,  9.1938e-01],\n",
       "           [ 1.3766e+00, -2.8880e-02, -3.7559e-01,  ..., -3.9570e-01,\n",
       "            -4.8153e-01, -4.3715e-01]],\n",
       "\n",
       "          [[ 3.1208e+00,  3.9899e+00,  2.9479e-01,  ...,  4.7024e+00,\n",
       "             6.4230e+00,  5.1758e+00],\n",
       "           [ 6.1907e+00,  6.6602e+00,  8.1359e+00,  ...,  9.3590e+00,\n",
       "             5.4751e+00,  4.4059e-01],\n",
       "           [ 3.4155e+00,  8.3546e+00,  6.8137e+00,  ...,  3.9353e+00,\n",
       "             6.2190e+00,  2.6967e+00],\n",
       "           ...,\n",
       "           [ 8.6950e+00,  9.6936e+00,  1.0505e+01,  ...,  6.3490e+00,\n",
       "            -1.4721e-01,  1.7977e+00],\n",
       "           [ 5.8470e+00,  6.3157e+00, -1.0769e-01,  ...,  4.3904e+00,\n",
       "             2.5635e+00,  2.8871e-01],\n",
       "           [ 5.5538e+00,  3.6585e+00,  4.9991e+00,  ...,  2.2023e-01,\n",
       "             5.6549e-01, -1.4077e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 2.2498e+00,  1.6437e+00,  2.1872e+00,  ...,  4.2605e+00,\n",
       "             5.5209e+00,  2.4209e+00],\n",
       "           [ 3.8031e+00,  3.6380e-01,  3.1469e+00,  ...,  4.6076e+00,\n",
       "             4.9680e+00,  7.7631e-01],\n",
       "           [ 1.2994e+00,  6.7083e+00,  3.6983e+00,  ...,  3.0138e+00,\n",
       "             6.2625e+00,  1.6270e+00],\n",
       "           ...,\n",
       "           [ 2.6076e+00,  5.5752e+00,  5.0760e+00,  ...,  3.0684e+00,\n",
       "             1.7676e+00,  2.9548e+00],\n",
       "           [ 6.4629e+00,  5.5870e+00,  4.6566e+00,  ...,  1.0217e+00,\n",
       "             4.4148e+00,  1.5885e+00],\n",
       "           [ 2.0123e+00,  1.0416e+00,  3.1659e+00,  ...,  2.1562e+00,\n",
       "             4.0177e-01,  1.0511e+00]],\n",
       "\n",
       "          [[ 3.9378e-02, -2.8306e-01, -3.4968e-01,  ...,  2.5858e+00,\n",
       "            -3.1513e-01, -9.6155e-02],\n",
       "           [-2.6865e-01, -3.4862e-01, -2.8460e-01,  ...,  3.5363e+00,\n",
       "             1.5583e+00, -1.3470e-01],\n",
       "           [-2.4403e-01, -1.8880e-01, -3.7819e-01,  ...,  6.4339e-01,\n",
       "             2.9875e+00,  2.8462e+00],\n",
       "           ...,\n",
       "           [ 5.0930e-01,  4.6778e+00, -1.7752e-01,  ...,  3.5471e+00,\n",
       "             7.1951e-02,  8.0500e-01],\n",
       "           [-2.3750e-01,  4.8907e+00,  3.2072e+00,  ...,  4.0845e+00,\n",
       "             3.0512e+00, -3.4720e-01],\n",
       "           [ 2.5448e-01,  1.7951e+00,  3.4705e+00,  ...,  4.6764e-01,\n",
       "             1.7032e+00, -1.7105e-01]],\n",
       "\n",
       "          [[ 4.0127e-01,  3.3396e-01,  3.9022e-02,  ...,  1.1000e-01,\n",
       "            -2.3600e-02, -4.1813e-02],\n",
       "           [-4.5902e-02, -1.3168e-02,  4.4037e-01,  ...,  1.2676e-01,\n",
       "             3.7156e-02, -1.9274e-02],\n",
       "           [ 1.4243e+00, -3.2221e-02,  2.6236e-01,  ...,  1.5018e-01,\n",
       "             3.4719e-01,  6.9135e-01],\n",
       "           ...,\n",
       "           [-3.2914e-02,  1.7419e-01,  5.7689e-01,  ...,  5.1290e-02,\n",
       "             1.6571e-02,  4.8389e-01],\n",
       "           [ 1.6692e-01,  1.5926e-01,  1.6373e-01,  ...,  3.7208e-01,\n",
       "             1.5477e+00,  5.5383e-02],\n",
       "           [ 6.9337e-01, -2.0561e-01, -1.0485e-02,  ...,  5.3283e-02,\n",
       "            -3.5011e-02, -4.9118e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-2.9506e-01,  6.6379e-01,  2.0072e+00,  ..., -4.1621e-01,\n",
       "            -2.1981e-01,  4.5471e-01],\n",
       "           [-1.7296e-01,  8.2167e-01,  2.2271e+00,  ...,  1.5621e-01,\n",
       "             8.3109e-02,  1.1357e+00],\n",
       "           [ 1.9643e+00, -3.9195e-01,  3.6542e+00,  ...,  6.1518e-01,\n",
       "            -1.9064e-01,  2.8507e-01],\n",
       "           ...,\n",
       "           [ 3.5592e+00, -3.3262e-01,  2.2951e+00,  ...,  2.0255e-01,\n",
       "            -2.8096e-01, -1.0308e-02],\n",
       "           [-4.8325e-03, -2.0813e-01,  2.1861e-01,  ..., -3.9988e-02,\n",
       "            -1.7459e-01,  2.0655e-01],\n",
       "           [ 1.2942e+00, -5.3635e-02,  2.1147e+00,  ..., -3.0501e-01,\n",
       "            -2.7825e-01,  7.5344e-01]],\n",
       "\n",
       "          [[-4.3309e-01, -3.1787e-01,  3.9125e-01,  ..., -2.8710e-01,\n",
       "            -5.8708e-01, -1.5469e-02],\n",
       "           [ 7.9254e-01, -7.0304e-01,  7.5854e-01,  ..., -5.8267e-01,\n",
       "            -8.0175e-01,  8.9395e-01],\n",
       "           [ 3.3466e-01, -7.9522e-01, -6.0758e-01,  ...,  1.5370e+00,\n",
       "             3.0148e-03,  1.7467e+00],\n",
       "           ...,\n",
       "           [ 5.1474e-02,  2.1416e+00, -6.0701e-01,  ...,  7.9521e-01,\n",
       "            -3.1063e-01, -3.4408e-01],\n",
       "           [-3.6095e-01,  1.8237e+00, -4.0645e-01,  ..., -1.7106e-01,\n",
       "            -6.1826e-01,  5.0157e-03],\n",
       "           [ 9.8181e-01,  1.4694e+00,  8.8236e-01,  ..., -3.8850e-01,\n",
       "            -2.6767e-01, -4.4943e-01]],\n",
       "\n",
       "          [[ 2.2096e+00, -1.9974e-01,  3.0606e+00,  ..., -2.2132e-01,\n",
       "             1.7372e+00,  2.1084e+00],\n",
       "           [ 4.3261e+00,  4.6881e+00,  5.2547e+00,  ...,  6.6722e+00,\n",
       "             5.7911e+00,  2.1941e+00],\n",
       "           [ 3.4260e+00,  6.8279e+00,  3.6317e+00,  ...,  3.3161e+00,\n",
       "             5.0185e+00,  2.6502e+00],\n",
       "           ...,\n",
       "           [ 7.4326e+00,  8.8817e+00,  6.1888e+00,  ...,  1.0901e+00,\n",
       "             2.8152e+00,  8.5373e-01],\n",
       "           [ 6.1413e+00,  8.9201e+00,  8.1038e+00,  ...,  6.1497e-01,\n",
       "             2.3721e+00,  9.5390e-01],\n",
       "           [ 5.7765e+00,  1.7505e+00,  5.1435e+00,  ...,  2.7897e+00,\n",
       "             1.4714e+00, -3.1327e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 3.1354e+00,  3.6786e+00,  2.0224e+00,  ...,  2.3875e+00,\n",
       "             3.9390e+00,  2.5018e+00],\n",
       "           [ 3.7276e+00,  6.2320e+00,  4.2522e+00,  ...,  7.4487e+00,\n",
       "             2.9150e+00,  3.2104e+00],\n",
       "           [ 6.5035e+00,  4.2692e+00,  3.9932e+00,  ...,  6.4586e+00,\n",
       "             6.3488e+00,  2.2025e+00],\n",
       "           ...,\n",
       "           [ 1.4380e+00,  6.1064e+00,  3.6226e+00,  ...,  8.6365e-01,\n",
       "             3.0415e+00,  2.8644e+00],\n",
       "           [ 5.1555e+00,  5.0026e+00,  6.9396e+00,  ...,  4.1030e+00,\n",
       "             1.9372e+00,  2.7383e+00],\n",
       "           [ 2.7922e+00,  5.1793e+00,  2.7292e+00,  ...,  1.6795e+00,\n",
       "             9.8905e-01,  8.3167e-01]],\n",
       "\n",
       "          [[-3.1973e-01, -1.8373e-01, -9.3354e-02,  ..., -2.2379e-01,\n",
       "            -1.9165e-01, -2.2671e-01],\n",
       "           [-3.9529e-01,  4.3032e-01,  1.5746e+00,  ...,  2.4515e+00,\n",
       "             3.2319e+00,  1.0231e+00],\n",
       "           [-4.4894e-01,  3.2515e-02,  2.8092e+00,  ..., -2.2880e-01,\n",
       "             3.6911e+00,  3.9933e-01],\n",
       "           ...,\n",
       "           [-2.8375e-01,  1.9068e+00, -3.2369e-01,  ..., -1.5261e-01,\n",
       "             2.7348e+00,  2.7845e+00],\n",
       "           [ 9.8154e-01,  2.6978e+00, -1.1105e-01,  ...,  1.0173e+00,\n",
       "            -2.0655e-01, -3.7069e-01],\n",
       "           [ 4.0666e-01,  2.2381e+00,  4.2383e+00,  ...,  1.5874e+00,\n",
       "             4.7237e-01,  1.3766e+00]],\n",
       "\n",
       "          [[ 8.4030e-01,  8.1442e-02,  1.7295e-01,  ...,  1.4119e-01,\n",
       "             1.5580e-01, -9.5294e-02],\n",
       "           [ 6.1718e-01,  1.0644e+00,  2.2820e+00,  ...,  4.5522e-01,\n",
       "             1.6110e-01,  2.3130e-02],\n",
       "           [ 5.1593e-02,  1.0690e-02,  1.9671e-01,  ...,  1.8991e+00,\n",
       "             1.0308e-01,  7.1928e-01],\n",
       "           ...,\n",
       "           [ 1.1644e-01,  1.8744e+00,  1.1113e+00,  ...,  6.4329e-01,\n",
       "             6.5646e-02,  5.0150e-02],\n",
       "           [ 2.0654e-01,  1.5917e-01,  1.1026e+00,  ...,  1.5105e-01,\n",
       "             1.3550e-01,  2.7254e-02],\n",
       "           [-2.5810e-01, -1.3752e-01,  2.9139e-01,  ..., -5.6016e-02,\n",
       "            -1.4275e-01, -7.9395e-02]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 8.5835e-01,  9.1114e-01, -3.3770e-01,  ...,  2.3126e-01,\n",
       "             2.4216e-01,  1.5014e-01],\n",
       "           [ 3.0958e+00,  2.0777e+00,  2.5077e+00,  ...,  1.9832e+00,\n",
       "             3.2025e+00,  3.4020e-01],\n",
       "           [ 1.1575e+00,  4.3864e+00,  2.4483e+00,  ...,  1.6622e+00,\n",
       "             2.1170e+00,  1.8535e+00],\n",
       "           ...,\n",
       "           [ 2.3765e+00,  3.4145e+00,  7.0588e-03,  ..., -3.4580e-01,\n",
       "            -2.4742e-01,  2.4230e-02],\n",
       "           [ 6.5245e-01, -2.6292e-01, -2.2196e-01,  ..., -1.4781e-01,\n",
       "            -2.0132e-01,  1.7412e-01],\n",
       "           [ 1.2567e+00,  8.6655e-02,  1.4742e+00,  ...,  3.5483e-01,\n",
       "             6.1737e-01,  8.6162e-01]],\n",
       "\n",
       "          [[-5.7758e-01, -6.2273e-01, -7.5846e-01,  ...,  1.4636e+00,\n",
       "            -1.3592e-01,  1.3706e+00],\n",
       "           [ 5.0791e-01,  7.3909e-01, -7.9665e-01,  ..., -7.6617e-01,\n",
       "             1.1294e+00,  1.8623e+00],\n",
       "           [ 1.8729e+00,  4.0717e-01, -7.3433e-01,  ...,  1.9725e-01,\n",
       "             1.2811e+00,  2.2986e+00],\n",
       "           ...,\n",
       "           [ 1.7467e+00,  2.2437e-01,  3.8184e-01,  ..., -7.9590e-01,\n",
       "            -6.3224e-01, -2.4669e-01],\n",
       "           [ 5.9263e-01,  1.5426e+00, -2.7906e-01,  ..., -6.6827e-01,\n",
       "            -8.3528e-01,  2.0640e-01],\n",
       "           [ 4.1387e-01,  2.6636e-01,  1.4179e-01,  ..., -4.1693e-01,\n",
       "            -3.8085e-01, -4.8351e-01]],\n",
       "\n",
       "          [[ 3.3150e+00,  2.7649e+00,  3.1049e+00,  ...,  3.8026e+00,\n",
       "             1.9825e+00,  2.2425e+00],\n",
       "           [ 4.4175e+00,  7.0905e+00,  6.1438e+00,  ...,  6.1816e+00,\n",
       "             4.9399e+00, -2.2078e-01],\n",
       "           [ 3.1116e+00,  5.9422e+00,  6.6555e+00,  ..., -1.5041e-01,\n",
       "             5.0261e-01,  2.1694e+00],\n",
       "           ...,\n",
       "           [ 6.7928e+00,  6.0983e+00,  9.3186e+00,  ...,  3.1029e+00,\n",
       "             2.3708e+00,  5.1705e-01],\n",
       "           [ 6.1407e+00,  5.5735e+00,  4.7863e+00,  ...,  5.2204e+00,\n",
       "             4.3013e+00,  9.7149e-01],\n",
       "           [ 4.4747e+00,  4.6552e+00,  5.9726e+00,  ...,  8.5761e-01,\n",
       "             2.5876e-01, -2.8064e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 4.4392e+00,  3.1889e+00,  4.3249e+00,  ...,  2.5133e+00,\n",
       "             4.3206e-01,  1.3198e+00],\n",
       "           [ 3.2219e+00,  4.6091e+00,  3.9721e+00,  ...,  6.9751e+00,\n",
       "             4.3673e+00,  1.6919e+00],\n",
       "           [ 5.5679e+00,  6.5196e+00,  4.4675e+00,  ...,  1.5084e+00,\n",
       "             4.8704e+00,  2.2246e+00],\n",
       "           ...,\n",
       "           [ 4.2322e+00,  3.5043e+00,  7.2317e+00,  ...,  4.7849e+00,\n",
       "             8.5167e+00,  1.4514e-01],\n",
       "           [ 1.0021e+00,  6.0145e+00,  5.5789e+00,  ...,  3.0108e+00,\n",
       "             4.0657e+00,  1.7881e+00],\n",
       "           [ 2.8826e+00,  2.5956e+00,  8.0068e-01,  ...,  9.5143e-01,\n",
       "             2.2170e+00,  1.3780e+00]],\n",
       "\n",
       "          [[-4.0804e-01,  5.1353e-01,  1.8895e-01,  ...,  1.6366e+00,\n",
       "             1.4191e+00,  1.0262e+00],\n",
       "           [-4.5368e-01,  6.1523e-02,  3.0693e+00,  ...,  1.4890e+00,\n",
       "             4.9950e+00, -5.2912e-01],\n",
       "           [-3.9202e-01,  1.6919e+00, -3.7092e-01,  ..., -1.7251e-01,\n",
       "            -8.6962e-02,  1.9636e+00],\n",
       "           ...,\n",
       "           [ 9.5597e-01,  1.5347e+00,  2.3829e+00,  ..., -2.1412e-01,\n",
       "             5.1451e+00,  3.7274e+00],\n",
       "           [ 1.0078e+00,  3.1885e-01,  6.7800e-02,  ...,  3.9243e+00,\n",
       "             6.1149e+00,  4.1680e+00],\n",
       "           [ 5.1477e-01,  3.3359e+00,  4.3416e+00,  ..., -1.7532e-01,\n",
       "             4.7115e+00,  1.3449e+00]],\n",
       "\n",
       "          [[ 5.6403e-01, -5.0222e-02,  5.7410e-02,  ...,  1.2814e-01,\n",
       "             2.3409e-01, -8.8406e-02],\n",
       "           [ 1.1118e-01,  2.6088e-01,  2.1255e-01,  ...,  1.8989e-01,\n",
       "             6.1268e-01,  2.1106e-02],\n",
       "           [ 7.2044e-03, -9.4458e-03,  5.1411e-01,  ..., -9.3851e-03,\n",
       "             6.3793e-02, -7.0255e-04],\n",
       "           ...,\n",
       "           [ 1.0996e+00,  1.4701e-01,  2.0273e-01,  ...,  4.0221e-02,\n",
       "             1.4075e-02,  1.1484e-02],\n",
       "           [-2.7664e-02,  5.2005e-01,  7.0841e-02,  ...,  1.2777e-01,\n",
       "             5.9229e-02,  3.3551e-02],\n",
       "           [-7.6608e-02,  1.0109e+00, -2.1661e-01,  ..., -1.7861e-01,\n",
       "            -7.2409e-02,  5.3282e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 7.9878e-01,  1.8917e+00, -2.3609e-01,  ...,  4.1120e-01,\n",
       "             1.1446e+00, -1.9012e-01],\n",
       "           [ 2.0777e+00,  6.1261e-01, -2.6203e-01,  ...,  8.3749e-03,\n",
       "             2.7487e-01,  2.4157e-01],\n",
       "           [ 1.0223e+00,  1.5508e-01,  1.4649e+00,  ..., -2.6711e-01,\n",
       "            -1.2245e-01,  2.7151e+00],\n",
       "           ...,\n",
       "           [ 1.2096e+00,  1.2430e+00,  7.2448e-01,  ...,  2.0000e+00,\n",
       "             1.0067e+00,  1.7431e+00],\n",
       "           [ 7.2695e-01,  9.9809e-01,  6.7846e-01,  ...,  4.7034e-01,\n",
       "            -1.8999e-01,  5.3775e-02],\n",
       "           [ 1.2771e+00,  2.2004e+00,  3.8808e-01,  ...,  3.0567e-01,\n",
       "            -1.0451e-01, -2.0582e-01]],\n",
       "\n",
       "          [[-4.3684e-01, -4.1798e-01, -6.2391e-01,  ...,  7.9459e-01,\n",
       "            -2.5667e-01,  1.2589e-01],\n",
       "           [ 7.1739e-01, -4.4230e-02, -6.2822e-01,  ..., -7.0222e-01,\n",
       "            -2.9721e-01,  1.3497e+00],\n",
       "           [-3.3531e-01, -6.6385e-01, -6.0308e-01,  ..., -4.9461e-01,\n",
       "            -7.4961e-01, -1.4596e-01],\n",
       "           ...,\n",
       "           [ 6.0129e-01,  5.5032e-02, -7.9942e-01,  ...,  1.8190e+00,\n",
       "            -7.0157e-01,  4.0697e+00],\n",
       "           [ 3.4240e+00,  2.0722e-01, -7.4451e-01,  ..., -6.0939e-01,\n",
       "             7.5339e-02, -5.0543e-01],\n",
       "           [ 1.6702e+00,  5.3253e-02,  3.0093e+00,  ...,  1.9482e-01,\n",
       "            -2.9961e-01, -4.2798e-01]],\n",
       "\n",
       "          [[-6.6868e-02,  3.4477e+00,  3.2547e+00,  ...,  5.8805e+00,\n",
       "             4.1113e+00,  1.5457e+00],\n",
       "           [ 3.6893e+00, -9.4441e-02,  5.0621e+00,  ...,  6.0592e+00,\n",
       "             6.5917e+00,  2.6753e+00],\n",
       "           [ 2.9142e+00,  6.3645e+00,  5.5881e+00,  ...,  5.2511e+00,\n",
       "             5.5122e+00,  2.6477e+00],\n",
       "           ...,\n",
       "           [ 5.4950e-02,  8.2276e+00,  6.5347e+00,  ...,  6.9034e+00,\n",
       "             6.6280e+00,  6.8231e-01],\n",
       "           [ 3.7424e+00,  5.3797e+00,  8.7797e+00,  ...,  5.1816e+00,\n",
       "             3.4775e+00,  1.2598e+00],\n",
       "           [ 5.3050e+00,  2.8654e+00,  1.0536e+00,  ...,  1.3649e+00,\n",
       "             9.3535e-03, -2.8843e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 3.4639e+00,  6.2249e+00,  3.3049e+00,  ...,  1.7393e+00,\n",
       "             4.3135e+00,  3.3738e+00],\n",
       "           [ 6.3574e+00,  7.2009e+00,  3.2989e+00,  ...,  4.6720e+00,\n",
       "             7.0176e+00,  3.2442e+00],\n",
       "           [ 5.4101e+00,  5.3423e-01,  2.9811e+00,  ...,  4.5426e+00,\n",
       "             1.3296e+00,  3.6202e+00],\n",
       "           ...,\n",
       "           [ 3.3944e+00,  4.7049e+00,  1.5233e+00,  ...,  4.1628e+00,\n",
       "             1.1926e+00,  1.6954e+00],\n",
       "           [ 6.9753e+00,  8.1467e+00,  4.2759e+00,  ...,  1.5140e+00,\n",
       "             3.0133e+00,  2.0724e+00],\n",
       "           [ 3.4880e+00,  3.4244e+00,  1.8861e+00,  ...,  5.2074e-01,\n",
       "             3.3100e+00,  7.3560e-01]],\n",
       "\n",
       "          [[-3.2503e-01, -3.2807e-01,  2.1992e-01,  ...,  1.1014e-01,\n",
       "            -1.9451e-01, -8.5526e-02],\n",
       "           [-3.9485e-01,  2.2440e+00, -1.6177e-01,  ...,  2.7144e+00,\n",
       "             2.1763e+00,  3.7365e+00],\n",
       "           [-4.2336e-01,  2.3266e+00,  1.1901e+00,  ...,  1.6008e+00,\n",
       "             5.6502e-01, -2.1636e-01],\n",
       "           ...,\n",
       "           [-2.4097e-02,  7.1006e+00, -3.9259e-01,  ..., -2.3427e-01,\n",
       "            -1.9765e-01,  2.4812e+00],\n",
       "           [-2.5209e-01,  2.5305e+00,  5.0399e+00,  ..., -2.3987e-01,\n",
       "            -1.0922e-01, -3.9058e-01],\n",
       "           [ 1.6980e+00,  4.5519e-01,  2.8404e+00,  ..., -3.7036e-01,\n",
       "             2.6665e-01,  9.4056e-03]],\n",
       "\n",
       "          [[-4.9679e-02,  9.0777e-01,  2.8506e-01,  ...,  1.0196e-01,\n",
       "            -3.1658e-02, -4.2042e-02],\n",
       "           [-2.4723e-02, -2.3120e-02,  6.8333e-01,  ..., -2.4482e-02,\n",
       "             4.6099e-02, -2.2489e-02],\n",
       "           [-5.2874e-02,  6.6818e-01,  1.9048e+00,  ...,  1.6428e-01,\n",
       "             1.8966e-01,  1.2285e-01],\n",
       "           ...,\n",
       "           [-7.4644e-02,  1.2449e+00,  3.8732e-02,  ...,  2.6556e+00,\n",
       "            -3.8852e-02,  2.0036e+00],\n",
       "           [ 1.0520e-01,  3.4278e-03,  8.0282e-01,  ...,  1.6842e-01,\n",
       "             1.8870e-01,  4.4838e-02],\n",
       "           [-2.7407e-01,  1.1987e+00, -1.5774e-01,  ...,  5.9844e-01,\n",
       "            -6.3233e-02,  2.1812e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-2.5643e-01, -3.4804e-01,  1.9974e+00,  ..., -4.0332e-01,\n",
       "             8.6192e-01,  2.0205e+00],\n",
       "           [ 2.0686e+00,  1.9646e+00,  1.0562e+00,  ...,  3.9411e-01,\n",
       "             1.1155e+00, -1.9970e-01],\n",
       "           [ 1.3915e+00,  1.2152e-01,  2.8651e-01,  ..., -2.2319e-01,\n",
       "            -2.0471e-01, -5.0205e-02],\n",
       "           ...,\n",
       "           [ 2.4153e+00, -2.1868e-01,  1.2562e+00,  ...,  1.4213e-01,\n",
       "             9.7797e-01,  1.8340e+00],\n",
       "           [-1.5704e-01,  1.0226e+00,  4.3263e+00,  ...,  3.0312e-01,\n",
       "            -3.2658e-01,  1.3744e+00],\n",
       "           [ 6.2867e-01, -1.9119e-01,  2.0013e-01,  ...,  9.7638e-01,\n",
       "            -2.6565e-01,  3.0074e-01]],\n",
       "\n",
       "          [[-5.1291e-01, -5.4559e-01, -6.7312e-01,  ..., -4.0296e-01,\n",
       "            -7.4293e-01,  5.6788e-01],\n",
       "           [-4.3232e-01,  1.3271e+00, -8.0814e-01,  ..., -5.8009e-01,\n",
       "            -7.3524e-01, -1.4234e-02],\n",
       "           [-4.7686e-01,  2.0273e+00,  1.1366e-01,  ..., -4.7329e-01,\n",
       "            -8.4046e-01,  3.3053e-01],\n",
       "           ...,\n",
       "           [-2.8089e-01,  2.2295e+00,  8.4053e-02,  ..., -6.9682e-01,\n",
       "            -7.5529e-01,  3.6991e-02],\n",
       "           [ 7.3032e-01,  3.3787e+00,  1.7943e+00,  ..., -6.2582e-01,\n",
       "            -7.2659e-01, -2.5150e-01],\n",
       "           [ 3.5825e-01,  2.7337e+00,  4.7283e-01,  ..., -4.0276e-01,\n",
       "            -4.5096e-01, -5.0045e-01]],\n",
       "\n",
       "          [[ 2.2315e+00,  4.7635e+00,  4.9347e+00,  ...,  3.7094e+00,\n",
       "             2.4900e+00,  7.8375e-01],\n",
       "           [ 5.1764e+00,  4.9765e+00,  6.6872e+00,  ...,  6.1376e+00,\n",
       "             3.5916e+00,  3.0997e-01],\n",
       "           [ 5.8591e+00,  6.4974e+00,  4.9392e+00,  ...,  7.7289e+00,\n",
       "             3.7976e+00,  8.6636e-01],\n",
       "           ...,\n",
       "           [ 3.9781e+00,  9.0553e+00,  5.4388e+00,  ..., -1.1412e-01,\n",
       "            -7.6973e-02,  2.3499e+00],\n",
       "           [ 5.2620e+00,  6.0513e+00,  7.3683e+00,  ...,  4.4949e+00,\n",
       "             3.8986e+00,  1.1580e+00],\n",
       "           [ 6.7540e+00,  4.2116e+00,  5.5188e+00,  ...,  1.0819e+00,\n",
       "             1.2816e+00, -2.9418e-01]]],\n",
       "\n",
       "\n",
       "         [[[ 3.9762e+00,  3.0775e+00,  4.9098e+00,  ...,  9.9297e-01,\n",
       "             3.3098e+00,  8.4455e-02],\n",
       "           [ 5.0287e+00,  3.8734e+00,  7.9582e+00,  ...,  3.2811e+00,\n",
       "             7.4567e+00,  2.1734e+00],\n",
       "           [ 5.6595e+00,  4.6611e+00,  6.8780e+00,  ...,  1.5510e+00,\n",
       "             4.7610e+00,  7.3409e-01],\n",
       "           ...,\n",
       "           [ 1.1336e+00,  1.5725e+00,  6.2613e+00,  ...,  2.2059e+00,\n",
       "             4.8504e+00,  1.5192e+00],\n",
       "           [ 2.3132e+00,  7.0427e+00,  8.1377e+00,  ...,  4.1972e-01,\n",
       "             4.3857e+00,  1.8789e+00],\n",
       "           [ 2.6954e+00,  2.4067e+00,  3.0356e+00,  ...,  1.1207e+00,\n",
       "             9.7884e-01,  6.1090e-01]],\n",
       "\n",
       "          [[-4.5933e-01, -2.5104e-02, -2.6129e-01,  ..., -3.3259e-01,\n",
       "            -2.8506e-02,  8.2084e-01],\n",
       "           [-3.9508e-01, -1.8499e-01,  2.0280e+00,  ...,  7.4828e-01,\n",
       "             4.0213e+00,  2.1003e+00],\n",
       "           [-4.3039e-01, -2.0034e-01, -2.9054e-01,  ...,  5.4208e+00,\n",
       "            -1.7472e-01,  2.1860e+00],\n",
       "           ...,\n",
       "           [-4.1012e-01,  9.3460e-02,  2.9557e+00,  ..., -1.4953e-01,\n",
       "             4.2967e+00,  2.6482e+00],\n",
       "           [-2.3446e-01,  2.4136e+00,  4.5958e+00,  ..., -1.0349e-01,\n",
       "             2.0414e+00,  2.8456e+00],\n",
       "           [-4.4958e-02,  2.3626e+00,  3.1306e+00,  ...,  1.1339e+00,\n",
       "             1.3131e+00,  1.7716e+00]],\n",
       "\n",
       "          [[ 3.7201e-01, -1.2766e-02,  1.8675e+00,  ..., -2.4700e-02,\n",
       "             4.0658e-01,  9.3858e-02],\n",
       "           [-3.6786e-02,  1.4515e-01,  1.6613e+00,  ...,  2.7089e+00,\n",
       "             1.7300e+00,  9.1544e-03],\n",
       "           [ 1.4333e-01,  1.7026e-02,  3.7289e-02,  ...,  2.8424e-01,\n",
       "             3.2342e-02,  7.8934e-03],\n",
       "           ...,\n",
       "           [ 9.4920e-02,  1.1557e-02,  6.7439e-01,  ...,  9.7594e-01,\n",
       "             1.4327e-01,  5.2625e-02],\n",
       "           [-8.6189e-02,  5.4843e-01,  1.5386e-02,  ...,  2.4633e+00,\n",
       "             1.2600e-01,  1.0903e+00],\n",
       "           [ 1.1124e-01, -2.0624e-01, -1.0045e-01,  ..., -1.5359e-01,\n",
       "            -4.5241e-02, -1.1721e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 8.3421e-01,  4.4727e+00, -2.7796e-01,  ...,  6.5858e-01,\n",
       "             6.0112e-01,  1.0168e+00],\n",
       "           [ 3.1310e-01,  5.8168e-01,  1.1697e+00,  ...,  1.7714e+00,\n",
       "            -1.9288e-01, -2.4145e-02],\n",
       "           [ 9.2221e-03, -2.2958e-01,  2.0709e+00,  ...,  1.9892e+00,\n",
       "             7.9338e-01, -1.0572e-02],\n",
       "           ...,\n",
       "           [ 8.8342e-01,  2.2774e-01, -3.2560e-01,  ...,  1.2710e+00,\n",
       "            -1.3775e-01,  4.8082e-02],\n",
       "           [ 5.0445e-01,  3.8027e+00, -3.2380e-01,  ...,  5.3604e-01,\n",
       "             2.9929e-01,  1.1428e+00],\n",
       "           [ 1.0282e+00,  1.6138e+00,  1.7999e-01,  ...,  4.7816e-01,\n",
       "             6.1702e-01,  2.6192e-01]],\n",
       "\n",
       "          [[-5.7137e-01, -2.8065e-01, -6.0356e-01,  ...,  2.1681e+00,\n",
       "            -1.2324e-01,  1.2910e+00],\n",
       "           [ 1.0526e+00,  3.3839e-01,  7.3711e-01,  ...,  1.2880e+00,\n",
       "            -6.1890e-01,  2.1741e+00],\n",
       "           [-3.6513e-01, -6.4415e-01, -5.8688e-01,  ..., -5.7004e-01,\n",
       "            -7.1348e-01,  3.4257e+00],\n",
       "           ...,\n",
       "           [ 9.7458e-01,  4.9774e+00, -7.4809e-01,  ..., -6.5440e-01,\n",
       "             7.9303e-01,  1.2825e+00],\n",
       "           [ 2.6977e+00,  3.2665e+00,  4.6553e+00,  ..., -5.2970e-01,\n",
       "             1.1127e+00, -5.3518e-01],\n",
       "           [ 6.8312e-02,  1.2676e+00,  5.0011e-01,  ..., -3.0287e-01,\n",
       "            -4.7658e-01, -3.5715e-01]],\n",
       "\n",
       "          [[ 4.3044e+00,  2.1605e+00,  3.1697e+00,  ...,  6.3192e+00,\n",
       "             4.0237e+00,  1.5275e+00],\n",
       "           [ 5.4913e+00,  6.5207e+00,  7.0391e+00,  ...,  3.6610e+00,\n",
       "             6.5977e+00,  4.2917e+00],\n",
       "           [ 4.2667e+00,  6.5342e+00,  6.8236e+00,  ...,  5.9863e+00,\n",
       "             6.0570e+00, -2.2261e-01],\n",
       "           ...,\n",
       "           [ 9.9087e+00,  1.0005e+01,  1.1631e+01,  ...,  4.0325e+00,\n",
       "             3.0479e+00,  2.2087e+00],\n",
       "           [ 8.7842e+00,  1.1405e+01,  7.2851e+00,  ...,  6.9074e+00,\n",
       "             6.3361e+00,  1.3605e+00],\n",
       "           [ 5.6812e+00,  3.5794e+00,  8.4711e-01,  ...,  1.5867e+00,\n",
       "             6.7298e-01, -2.7978e-01]]]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(model_body_output).shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0483])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tail_weight_grad.mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6422/1550020374.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1675740268907/work/aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  model_body.block_9.trans.wide_focus.conv4.weight.data.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 8, 8])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_body.block_9.trans.wide_focus.conv4.weight.data.T.shape\n",
    "# model_body.block_9.trans.wide_focus.conv4.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "assigned grad has data of a different size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer_body\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      3\u001b[0m hidden_grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mrelu(model_body\u001b[39m.\u001b[39mblock_9\u001b[39m.\u001b[39mtrans\u001b[39m.\u001b[39mwide_focus\u001b[39m.\u001b[39mconv4\u001b[39m.\u001b[39mweight)\u001b[39m.\u001b[39mT, tail_weight_grad)\n\u001b[0;32m----> 4\u001b[0m model_body\u001b[39m.\u001b[39;49mblock_9\u001b[39m.\u001b[39;49mtrans\u001b[39m.\u001b[39;49mwide_focus\u001b[39m.\u001b[39;49mconv4\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mgrad \u001b[39m=\u001b[39m hidden_grad\u001b[39m.\u001b[39mT\u001b[39m#.mean(dim=0, keepdim=True)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: assigned grad has data of a different size"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    optimizer_body.zero_grad()\n",
    "    hidden_grad = torch.matmul(nn.functional.relu(model_body.block_9.trans.wide_focus.conv4.weight).T, tail_weight_grad)\n",
    "    model_body.block_9.trans.wide_focus.conv4.weight.grad = hidden_grad.T#.mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 3, 3]) and output[0] has a shape of torch.Size([8, 8, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_body\u001b[39m.\u001b[39;49mblock_9\u001b[39m.\u001b[39;49mtrans\u001b[39m.\u001b[39;49mwide_focus\u001b[39m.\u001b[39;49mconv4\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mbackward(hidden_grad\u001b[39m.\u001b[39;49mT)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.9/site-packages/torch/autograd/__init__.py:190\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[1;32m    187\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[1;32m    189\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[0;32m--> 190\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.9/site-packages/torch/autograd/__init__.py:68\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf `is_grads_batched=True`, we interpret the first \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mdimension of each grad_output as the batch dimension. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mThe sizes of the remaining dimensions are expected to match \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mIf you only want some tensors in `grad_output` to be considered \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mbatched, consider using vmap.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMismatch in shape: grad_output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(grads\u001b[39m.\u001b[39mindex(grad)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(grad_shape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m and output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(outputs\u001b[39m.\u001b[39mindex(out)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m                            \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out_shape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39m!=\u001b[39m grad\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex:\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFor complex Tensors, both grad_output and output\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m are required to have the same dtype.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m Mismatch in dtype: grad_output[\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m                        \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(outputs\u001b[39m.\u001b[39mindex(out)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m] has a dtype of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m                        \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(out\u001b[39m.\u001b[39mdtype) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Mismatch in shape: grad_output[0] has a shape of torch.Size([8, 3, 3]) and output[0] has a shape of torch.Size([8, 8, 3, 3])."
     ]
    }
   ],
   "source": [
    "model_body.block_9.trans.wide_focus.conv4.weight.backward(hidden_grad.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_body.block_9.trans.wide_focus.conv4.weight.grad.data.zero_()\n",
    "model_body.block_9.trans.wide_focus.conv4.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 3])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tail_weight_grad, model_body.block_9.trans.wide_focus.conv4.weight.T).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_5.layernorm.weight\n",
      "block_5.layernorm.bias\n",
      "block_5.conv1.weight\n",
      "block_5.conv1.bias\n",
      "block_5.conv2.weight\n",
      "block_5.conv2.bias\n",
      "block_5.trans.attention_output.conv_q.weight\n",
      "block_5.trans.attention_output.conv_q.bias\n",
      "block_5.trans.attention_output.layernorm_q.weight\n",
      "block_5.trans.attention_output.layernorm_q.bias\n",
      "block_5.trans.attention_output.conv_k.weight\n",
      "block_5.trans.attention_output.conv_k.bias\n",
      "block_5.trans.attention_output.layernorm_k.weight\n",
      "block_5.trans.attention_output.layernorm_k.bias\n",
      "block_5.trans.attention_output.conv_v.weight\n",
      "block_5.trans.attention_output.conv_v.bias\n",
      "block_5.trans.attention_output.layernorm_v.weight\n",
      "block_5.trans.attention_output.layernorm_v.bias\n",
      "block_5.trans.attention_output.attention.in_proj_weight\n",
      "block_5.trans.attention_output.attention.in_proj_bias\n",
      "block_5.trans.attention_output.attention.out_proj.weight\n",
      "block_5.trans.attention_output.attention.out_proj.bias\n",
      "block_5.trans.conv1.weight\n",
      "block_5.trans.conv1.bias\n",
      "block_5.trans.layernorm.weight\n",
      "block_5.trans.layernorm.bias\n",
      "block_5.trans.wide_focus.conv1.weight\n",
      "block_5.trans.wide_focus.conv1.bias\n",
      "block_5.trans.wide_focus.conv2.weight\n",
      "block_5.trans.wide_focus.conv2.bias\n",
      "block_5.trans.wide_focus.conv3.weight\n",
      "block_5.trans.wide_focus.conv3.bias\n",
      "block_5.trans.wide_focus.conv4.weight\n",
      "block_5.trans.wide_focus.conv4.bias\n",
      "block_6.layernorm.weight\n",
      "block_6.layernorm.bias\n",
      "block_6.conv1.weight\n",
      "block_6.conv1.bias\n",
      "block_6.conv2.weight\n",
      "block_6.conv2.bias\n",
      "block_6.conv3.weight\n",
      "block_6.conv3.bias\n",
      "block_6.trans.attention_output.conv_q.weight\n",
      "block_6.trans.attention_output.conv_q.bias\n",
      "block_6.trans.attention_output.layernorm_q.weight\n",
      "block_6.trans.attention_output.layernorm_q.bias\n",
      "block_6.trans.attention_output.conv_k.weight\n",
      "block_6.trans.attention_output.conv_k.bias\n",
      "block_6.trans.attention_output.layernorm_k.weight\n",
      "block_6.trans.attention_output.layernorm_k.bias\n",
      "block_6.trans.attention_output.conv_v.weight\n",
      "block_6.trans.attention_output.conv_v.bias\n",
      "block_6.trans.attention_output.layernorm_v.weight\n",
      "block_6.trans.attention_output.layernorm_v.bias\n",
      "block_6.trans.attention_output.attention.in_proj_weight\n",
      "block_6.trans.attention_output.attention.in_proj_bias\n",
      "block_6.trans.attention_output.attention.out_proj.weight\n",
      "block_6.trans.attention_output.attention.out_proj.bias\n",
      "block_6.trans.conv1.weight\n",
      "block_6.trans.conv1.bias\n",
      "block_6.trans.layernorm.weight\n",
      "block_6.trans.layernorm.bias\n",
      "block_6.trans.wide_focus.conv1.weight\n",
      "block_6.trans.wide_focus.conv1.bias\n",
      "block_6.trans.wide_focus.conv2.weight\n",
      "block_6.trans.wide_focus.conv2.bias\n",
      "block_6.trans.wide_focus.conv3.weight\n",
      "block_6.trans.wide_focus.conv3.bias\n",
      "block_6.trans.wide_focus.conv4.weight\n",
      "block_6.trans.wide_focus.conv4.bias\n",
      "block_7.layernorm.weight\n",
      "block_7.layernorm.bias\n",
      "block_7.conv1.weight\n",
      "block_7.conv1.bias\n",
      "block_7.conv2.weight\n",
      "block_7.conv2.bias\n",
      "block_7.conv3.weight\n",
      "block_7.conv3.bias\n",
      "block_7.trans.attention_output.conv_q.weight\n",
      "block_7.trans.attention_output.conv_q.bias\n",
      "block_7.trans.attention_output.layernorm_q.weight\n",
      "block_7.trans.attention_output.layernorm_q.bias\n",
      "block_7.trans.attention_output.conv_k.weight\n",
      "block_7.trans.attention_output.conv_k.bias\n",
      "block_7.trans.attention_output.layernorm_k.weight\n",
      "block_7.trans.attention_output.layernorm_k.bias\n",
      "block_7.trans.attention_output.conv_v.weight\n",
      "block_7.trans.attention_output.conv_v.bias\n",
      "block_7.trans.attention_output.layernorm_v.weight\n",
      "block_7.trans.attention_output.layernorm_v.bias\n",
      "block_7.trans.attention_output.attention.in_proj_weight\n",
      "block_7.trans.attention_output.attention.in_proj_bias\n",
      "block_7.trans.attention_output.attention.out_proj.weight\n",
      "block_7.trans.attention_output.attention.out_proj.bias\n",
      "block_7.trans.conv1.weight\n",
      "block_7.trans.conv1.bias\n",
      "block_7.trans.layernorm.weight\n",
      "block_7.trans.layernorm.bias\n",
      "block_7.trans.wide_focus.conv1.weight\n",
      "block_7.trans.wide_focus.conv1.bias\n",
      "block_7.trans.wide_focus.conv2.weight\n",
      "block_7.trans.wide_focus.conv2.bias\n",
      "block_7.trans.wide_focus.conv3.weight\n",
      "block_7.trans.wide_focus.conv3.bias\n",
      "block_7.trans.wide_focus.conv4.weight\n",
      "block_7.trans.wide_focus.conv4.bias\n",
      "block_8.layernorm.weight\n",
      "block_8.layernorm.bias\n",
      "block_8.conv1.weight\n",
      "block_8.conv1.bias\n",
      "block_8.conv2.weight\n",
      "block_8.conv2.bias\n",
      "block_8.conv3.weight\n",
      "block_8.conv3.bias\n",
      "block_8.trans.attention_output.conv_q.weight\n",
      "block_8.trans.attention_output.conv_q.bias\n",
      "block_8.trans.attention_output.layernorm_q.weight\n",
      "block_8.trans.attention_output.layernorm_q.bias\n",
      "block_8.trans.attention_output.conv_k.weight\n",
      "block_8.trans.attention_output.conv_k.bias\n",
      "block_8.trans.attention_output.layernorm_k.weight\n",
      "block_8.trans.attention_output.layernorm_k.bias\n",
      "block_8.trans.attention_output.conv_v.weight\n",
      "block_8.trans.attention_output.conv_v.bias\n",
      "block_8.trans.attention_output.layernorm_v.weight\n",
      "block_8.trans.attention_output.layernorm_v.bias\n",
      "block_8.trans.attention_output.attention.in_proj_weight\n",
      "block_8.trans.attention_output.attention.in_proj_bias\n",
      "block_8.trans.attention_output.attention.out_proj.weight\n",
      "block_8.trans.attention_output.attention.out_proj.bias\n",
      "block_8.trans.conv1.weight\n",
      "block_8.trans.conv1.bias\n",
      "block_8.trans.layernorm.weight\n",
      "block_8.trans.layernorm.bias\n",
      "block_8.trans.wide_focus.conv1.weight\n",
      "block_8.trans.wide_focus.conv1.bias\n",
      "block_8.trans.wide_focus.conv2.weight\n",
      "block_8.trans.wide_focus.conv2.bias\n",
      "block_8.trans.wide_focus.conv3.weight\n",
      "block_8.trans.wide_focus.conv3.bias\n",
      "block_8.trans.wide_focus.conv4.weight\n",
      "block_8.trans.wide_focus.conv4.bias\n",
      "block_9.layernorm.weight\n",
      "block_9.layernorm.bias\n",
      "block_9.conv1.weight\n",
      "block_9.conv1.bias\n",
      "block_9.conv2.weight\n",
      "block_9.conv2.bias\n",
      "block_9.conv3.weight\n",
      "block_9.conv3.bias\n",
      "block_9.trans.attention_output.conv_q.weight\n",
      "block_9.trans.attention_output.conv_q.bias\n",
      "block_9.trans.attention_output.layernorm_q.weight\n",
      "block_9.trans.attention_output.layernorm_q.bias\n",
      "block_9.trans.attention_output.conv_k.weight\n",
      "block_9.trans.attention_output.conv_k.bias\n",
      "block_9.trans.attention_output.layernorm_k.weight\n",
      "block_9.trans.attention_output.layernorm_k.bias\n",
      "block_9.trans.attention_output.conv_v.weight\n",
      "block_9.trans.attention_output.conv_v.bias\n",
      "block_9.trans.attention_output.layernorm_v.weight\n",
      "block_9.trans.attention_output.layernorm_v.bias\n",
      "block_9.trans.attention_output.attention.in_proj_weight\n",
      "block_9.trans.attention_output.attention.in_proj_bias\n",
      "block_9.trans.attention_output.attention.out_proj.weight\n",
      "block_9.trans.attention_output.attention.out_proj.bias\n",
      "block_9.trans.conv1.weight\n",
      "block_9.trans.conv1.bias\n",
      "block_9.trans.layernorm.weight\n",
      "block_9.trans.layernorm.bias\n",
      "block_9.trans.wide_focus.conv1.weight\n",
      "block_9.trans.wide_focus.conv1.bias\n",
      "block_9.trans.wide_focus.conv2.weight\n",
      "block_9.trans.wide_focus.conv2.bias\n",
      "block_9.trans.wide_focus.conv3.weight\n",
      "block_9.trans.wide_focus.conv3.bias\n",
      "block_9.trans.wide_focus.conv4.weight\n",
      "block_9.trans.wide_focus.conv4.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_body.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
